{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Piyush Tada](https://www.linkedin.com/in/piyushtada/)  \n",
    "**Python version:**  x.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading important libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "import nbconvert\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getting_data_ready():\n",
    "    \n",
    "    \"\"\"This fuction load all the data and split it.\n",
    "    To make life simple of loading and checking performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # for loading all the data\n",
    "    df = pd.read_csv('./data/scaled_datatrainingcopy.csv')\n",
    "    df_test1 = pd.read_csv('./data/scaled_datatestcopy.csv')\n",
    "    df_test2 = pd.read_csv('./data/scaled_datatest2copy.csv')\n",
    "\n",
    "    class_name = \"Occupancy\"\n",
    "\n",
    "    attributes = [col for col in df.columns if col != class_name]\n",
    "    X = df[attributes].values # this is used so that you can get np value\n",
    "    y = df[class_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "    attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test1 = df_test1[attributes].values\n",
    "    y_test1 = df_test1[class_name]\n",
    "\n",
    "\n",
    "    attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test2 = df_test2[attributes].values\n",
    "    y_test2 = df_test2[class_name]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2 = getting_data_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-0.12317009 -0.16808266  0.34852348  0.08131454  0.15719227  0.1239484 ]\n",
      "Intercept: \n",
      " 0.13205106384676116\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', reg.coef_)\n",
    "print('Intercept: \\n', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.891\n",
      "MSE: 0.018\n",
      "MAE: 0.082\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "print('R2: %.3f' % r2_score(y_test, y_pred))\n",
    "print('MSE: %.3f' % mean_squared_error(y_test, y_pred))\n",
    "print('MAE: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2:\n",
    "### r-squared\n",
    "The close to 1 it is the better then it says that the value us used for prediction is moving with the final value that you want.\n",
    "\n",
    "https://www.investopedia.com/terms/r/r-squared.asp\n",
    "\n",
    "# MSE: \n",
    "### mean squared error (MSE)\n",
    "It calulate the distace of value from the mean:\n",
    "\n",
    "An MSE of zero, meaning that the estimator <b> Z </b> predicts observations of the parameter <b> X </b>  with perfect accuracy, is the ideal, but is typically not possible.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "# MAE:\n",
    "### mean absolute error (MAE)\n",
    "\n",
    "It's basically the absolute error |x-x| so lower the value the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv does not exist: '/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f254ac8365ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#loading scaled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv does not exist: '/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv'"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/preprocessdatatrainingcopy.csv')\n",
    "\n",
    "#loading scaled data\n",
    "df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making this code for diffent tryes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = 'Humidity' #['Temperature', 'Humidity', 'Light', \n",
    "to_find = 'Light'   #'CO2', 'HumidityRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression() \n",
    "reg.fit(df[[to_use]], df[to_find])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[[to_use]]), len(df[to_find]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(df[[to_use]])\n",
    "r = r2_score(df[to_find], y_pred)\n",
    "print(round(r,ndigits=3))\n",
    "print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(df[[to_use]])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.style.context('ggplot')\n",
    "plt.xlabel(to_use)\n",
    "plt.ylabel(to_find)\n",
    "plt.scatter(df[to_use], df[to_find])\n",
    "plt.plot(df[[to_use]], y_pred, color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Temperature', 'Humidity', 'Light','CO2', 'HumidityRatio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got itertools from here https://stackoverflow.com/questions/464864/how-to-get-all-possible-combinations-of-a-list-s-elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "for first , second in itertools.combinations(options,2):\n",
    "    print(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression in 2 dimensions\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results\n",
    "\n",
    "reg = [(\"LinearRegression\",LinearRegression()), (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "\n",
    "df_report = pd.DataFrame(columns=[\"Model\",'R2', 'MSE', 'MAE', 'Coefficients','Intercept'])\n",
    "\n",
    "\n",
    "#y_test = X_test.T[0].reshape(-1, 1)\n",
    "#y_train = X_train.T[0].reshape(-1, 1)\n",
    "\n",
    "for name, reg in reg:\n",
    "    \n",
    "    print(\"========Results of {}============\".format(name))\n",
    "    reg.fit(X_train.T[0].reshape(-1, 1), y_train)\n",
    "    y_pred = reg.predict(X_test.T[0].reshape(-1, 1))\n",
    "    \n",
    "    print('R2: %.3f' % r2_score(y_test, y_pred))\n",
    "    print('MSE: %.3f' % mean_squared_error(y_test, y_pred))\n",
    "    print('MAE: %.3f' % mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "#     #this is the parameters that define how the line will look\n",
    "#     print('Coefficients: ', reg.coef_)\n",
    "#     print('Intercept: ', reg.intercept_)\n",
    "    \n",
    "#     plt.scatter(X_test.T[0], y_test,  color='black')\n",
    "#     plt.plot(X_test.T[0], y_pred, color='blue', linewidth=3)\n",
    "#     df_report[\"Model\"] = name\n",
    "#     df_report['R2'] = r2_score(y_test, y_pred)\n",
    "#     df_report['MSE'] = mean_squared_error(y_test, y_pred)\n",
    "#     df_report['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "# #     df_report['Coefficients'] = reg.coef_\n",
    "# #     df_report['Intercept'] = reg.intercept_\n",
    "#     df_report = pd.concat([df_report, df_report], axis=0, ignore_index=True )\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving charts\n",
    "\n",
    "file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_ROC_curve_\" + num + \".png\"\n",
    "       plt.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_model = \"Linear Regression\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train.T[0].reshape(-1, 1)## Linear Regression in 2 dimensions\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results\n",
    "\n",
    "reg = [(\"LinearRegression\",LinearRegression()), (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "\n",
    "df_report = pd.DataFrame(columns=[\"Model\",'R2', 'MSE', 'MAE', 'Coefficients','Intercept'])\n",
    "\n",
    "\n",
    "# y_test = X_test.T[1].reshape(-1, 1)\n",
    "# y_train = X_train.T[1]\n",
    "\n",
    "for name, reg in reg:\n",
    "    \n",
    "    print(\"========Results of {}============\".format(name))\n",
    "    reg.fit(X_train.T[0].reshape(-1, 1), y_train)\n",
    "    y_pred = reg.predict(X_test.T[0].reshape(-1, 1))\n",
    "    \n",
    "    print('R2: %.3f' % r2_score(y_test, y_pred))\n",
    "    print('MSE: %.3f' % mean_squared_error(y_test, y_pred))\n",
    "    print('MAE: %.3f' % mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    #this is the parameters that define how the line will look\n",
    "    print('Coefficients: ', reg.coef_)\n",
    "    print('Intercept: ', reg.intercept_)\n",
    "    \n",
    "    plt.scatter(X_test.T[0], y_test,  color='black')\n",
    "    plt.plot(X_test.T[0], y_pred, color='blue', linewidth=3)\n",
    "    df_report[\"Model\"] = name\n",
    "    df_report['R2'] = r2_score(y_test, y_pred)\n",
    "    df_report['MSE'] = mean_squared_error(y_test, y_pred)\n",
    "    df_report['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "    df_report['Coefficients'] = reg.coef_\n",
    "    df_report['Intercept'] = reg.intercept_\n",
    "    df_report = pd.concat([df_report, df_report], axis=1)\n",
    "    file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_chart_\" + name + \".png\"\n",
    "\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Lasso()\n",
    "reg.fit(X_train.T[0].reshape(-1, 1), y_train)\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "print('Intercept: \\n', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test.T[0].reshape(-1, 1))\n",
    "print('R2: %.3f' % r2_score(y_test, y_pred))\n",
    "print('MSE: %.3f' % mean_squared_error(y_test, y_pred))\n",
    "print('MAE: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.T[0], y_test,  color='black')\n",
    "plt.plot(X_test.T[0], y_pred, color='blue', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Ridge()\n",
    "reg.fit(X_train.T[0].reshape(-1, 1), y_train)\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "print('Intercept: \\n', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test.T[0].reshape(-1, 1))\n",
    "print('R2: %.3f' % r2_score(y_test, y_pred))\n",
    "print('MSE: %.3f' % mean_squared_error(y_test, y_pred))\n",
    "print('MAE: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.T[0], y_test,  color='black')\n",
    "plt.plot(X_test.T[0], y_pred, color='blue', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with preprocced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/preprocessdatatrainingcopy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['CO2']\n",
    "class_name = \"Occupancy\"\n",
    "attributes = [col for col in df.columns if col != class_name]\n",
    "X = df[selected_columns].values\n",
    "y = df[class_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(selected_columns[0], fontsize=16)\n",
    "plt.ylabel('Occupancy', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = expit(sorted(X_test) * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(sorted(X_test), loss, color='red', linewidth=3)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.xlabel(selected_columns[0], fontsize=16)\n",
    "plt.ylabel('Occupancy', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "\n",
    "loss = expit(sorted(X_test) * clf.coef_ + clf.intercept_).ravel()\n",
    "plt.plot(sorted(X_test), loss, color='orange', linewidth=3)\n",
    "\n",
    "plt.plot(sorted(X_test), reg.coef_ * sorted(X_test) + reg.intercept_, color='red', linewidth=3)\n",
    "\n",
    "\n",
    "plt.xlabel(selected_columns[0], fontsize=16)\n",
    "plt.ylabel('Occupancy', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "https://realpython.com/logistic-regression-python/\n",
    "\n",
    "Here I am doing exprement first with only CO2 and testing the result and then later with CO2 and Light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "Logistic regression is a fundamental classification technique. It belongs to the group of linear classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_ready():\n",
    "\n",
    "    # for loading all the data\n",
    "    df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')\n",
    "    df_test1 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatestcopy.csv')\n",
    "    df_test2 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatest2copy.csv')\n",
    "\n",
    "    class_name = \"Occupancy\"\n",
    "    selected_columns = ['CO2']\n",
    "    \n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X = df[selected_columns].values\n",
    "    y = df[class_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test1 = df_test1[selected_columns].values\n",
    "    y_test1 = df_test1[class_name]\n",
    "\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test2 = df_test2[selected_columns].values\n",
    "    y_test2 = df_test2[class_name]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2 = getting_data_ready()\n",
    "\n",
    "# this is list to be used in testing automation\n",
    "\n",
    "tests = [(\"Training\", X_test,y_test),(\"Test_1\", X_test1,y_test1),\n",
    "         (\"Test_2\", X_test2, y_test2)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_report(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        print('\\n ===============Results for {} ================== \\n'.format(num))\n",
    "        print('Accuracy %s' % accuracy_score(results, y_pred))\n",
    "        print('F1-score %s' % f1_score(results, y_pred, average=None))\n",
    "        print(classification_report(results, y_pred))\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_roc(results, y_score)\n",
    "        plot_lift_curve(results, y_score)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_report(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame()\n",
    "\n",
    "for num, test, results in tests:\n",
    "    \n",
    "    y_pred = clf.predict(test)\n",
    "    results = pd.DataFrame(classification_report(results, y_pred, output_dict=True))\n",
    "    print(results.T)\n",
    "    df_report = pd.concat([df_report, results.T], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_results = \"/Users/piyush2017/Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this code will delete unwanted things\n",
    "\n",
    "try:\n",
    "    df_report.drop(['support'], axis=1, inplace=True)\n",
    "    df_report.drop(['macro avg','weighted avg'], axis=0,inplace=True)\n",
    "\n",
    "except:\n",
    "    pass \n",
    "\n",
    "file_name = path_to_save_results + \"res.xlsx\"\n",
    "\n",
    "df_report.to_excel(file_name)\n",
    "df_report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "    reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.show()\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "\n",
    "    print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "    print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "    print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))\n",
    "    \n",
    "    # to get two remaing values\n",
    "    print('Coefficients: ', reg.coef_)\n",
    "    print('Intercept: ', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first , second in itertools.combinations(options,2):\n",
    "    print(first, second)\n",
    "    get_every_thing(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### trying to do all the three "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_ready():\n",
    "\n",
    "    # for loading all the data\n",
    "    df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')\n",
    "    df_test1 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatestcopy.csv')\n",
    "    df_test2 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatest2copy.csv')\n",
    "\n",
    "    class_name = \"Occupancy\"\n",
    "    selected_columns = ['CO2','Light']\n",
    "    \n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X = df[selected_columns].values\n",
    "    y = df[class_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test1 = df_test1[selected_columns].values\n",
    "    y_test1 = df_test1[class_name]\n",
    "\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test2 = df_test2[selected_columns].values\n",
    "    y_test2 = df_test2[class_name]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2 = getting_data_ready()\n",
    "\n",
    "# this is list to be used in testing automation\n",
    "\n",
    "tests = [(\"Training\", X_test,y_test),(\"Test_1\", X_test1,y_test1),\n",
    "         (\"Test_2\", X_test2, y_test2)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_model = \"LogisticRegression\"\n",
    "\n",
    "def show_report_chart_lift(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_lift_curve(results, y_score)\n",
    "        file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_lift_curve_\" + num + \".png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.show()\n",
    "        \n",
    "def show_report_chart_roc(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_roc(results, y_score)\n",
    "        file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_ROC_curve_\" + num + \".png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_report_chart_lift(tests)\n",
    "show_report_chart_roc(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame()\n",
    "\n",
    "for num, test, results in tests:\n",
    "    \n",
    "    y_pred = clf.predict(test)\n",
    "    results = pd.DataFrame(classification_report(results, y_pred, output_dict=True))\n",
    "    print(results.T)\n",
    "    df_report = pd.concat([df_report, results.T], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this code will delete unwanted things\n",
    "\n",
    "df_report.drop(['support'], axis=1, inplace=True)\n",
    "df_report.drop(['macro avg','weighted avg'], axis=0,inplace=True)\n",
    "\n",
    "df_report.to_excel('/Users/piyush2017/Downloads/res.xlsx')\n",
    "df_report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "sns.heatmap(cm, annot=True,fmt=\"d\",cmap='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with all the atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_ready():\n",
    "\n",
    "    # for loading all the data\n",
    "    df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')\n",
    "    df_test1 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatestcopy.csv')\n",
    "    df_test2 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatest2copy.csv')\n",
    "\n",
    "    class_name = \"Occupancy\"\n",
    "    selected_columns = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']\n",
    "    \n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X = df[selected_columns]\n",
    "    y = df[class_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test1 = df_test1[selected_columns].values\n",
    "    y_test1 = df_test1[class_name]\n",
    "\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test2 = df_test2[selected_columns].values\n",
    "    y_test2 = df_test2[class_name]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2 = getting_data_ready()\n",
    "\n",
    "# this is list to be used in testing automation\n",
    "\n",
    "tests = [(\"Training\", X_test,y_test),(\"Test_1\", X_test1,y_test1),\n",
    "         (\"Test_2\", X_test2, y_test2)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_report(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        print('\\n ===============Results for {} ================== \\n'.format(num))\n",
    "        print('Accuracy %s' % accuracy_score(results, y_pred))\n",
    "        print('F1-score %s' % f1_score(results, y_pred, average=None))\n",
    "        print(classification_report(results, y_pred))\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_roc(results, y_score)\n",
    "        plot_lift_curve(results, y_score)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_report(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame()\n",
    "\n",
    "for num, test, results in tests:\n",
    "    \n",
    "    y_pred = clf.predict(test)\n",
    "    results = pd.DataFrame(classification_report(results, y_pred, output_dict=True))\n",
    "    print(results.T)\n",
    "    df_report = pd.concat([df_report, results.T], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_results = \"/Users/piyush2017/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this code will delete unwanted things\n",
    "\n",
    "try:\n",
    "    df_report.drop(['support'], axis=1, inplace=True)\n",
    "    df_report.drop(['macro avg','weighted avg'], axis=0,inplace=True)\n",
    "\n",
    "except:\n",
    "    pass \n",
    "\n",
    "file_name = path_to_save_results + \"res.xlsx\"\n",
    "\n",
    "df_report.to_excel(file_name)\n",
    "df_report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_model = \"LogisticRegression\"\n",
    "\n",
    "def show_report_chart_lift(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_lift_curve(results, y_score)\n",
    "        file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_lift_curve_\" + num + \".png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.show()\n",
    "        \n",
    "def show_report_chart_roc(tests):\n",
    "    for num, test, results in tests:\n",
    "\n",
    "        y_pred = clf.predict(test)\n",
    "        y_score = clf.predict_proba(test)\n",
    "        plot_roc(results, y_score)\n",
    "        file_name = \"/Users/piyush2017/Downloads/\" + name_of_model + \"_ROC_curve_\" + num + \".png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_report_chart_lift(tests)\n",
    "show_report_chart_roc(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame(columns=[\"Model\",'R2', 'MSE', 'MAE', 'Coefficients','Intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_data_ready():\n",
    "\n",
    "    # for loading all the data\n",
    "    df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')\n",
    "    df_test1 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatestcopy.csv')\n",
    "    df_test2 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatest2copy.csv')\n",
    "\n",
    "    class_name = \"Occupancy\"\n",
    "    selected_columns = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio', 'Week_day']\n",
    "    \n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X = df[selected_columns]\n",
    "    y = df[class_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test1 = df_test1[selected_columns].values\n",
    "    y_test1 = df_test1[class_name]\n",
    "\n",
    "\n",
    "    #attributes = [col for col in df.columns if col != class_name]\n",
    "    X_test2 = df_test2[selected_columns].values\n",
    "    y_test2 = df_test2[class_name]\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_test1, y_test1, X_test2, y_test2 = getting_data_ready()\n",
    "\n",
    "# this is list to be used in testing automation\n",
    "\n",
    "tests = [(\"Training\", X_test,y_test),(\"Test_1\", X_test1,y_test1),\n",
    "         (\"Test_2\", X_test2, y_test2)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = reg = Ridge()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = X_train.columns\n",
    "\n",
    "coef = pd.Series(clf.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = reg = Lasso()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = X_train.columns\n",
    "\n",
    "coef = pd.Series(clf.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "    \n",
    "    col2 = [x for x in col if x != i]\n",
    "    for j in col2:\n",
    "        print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ij = 'Light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([if x is not ij for x in col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in col if x != 'Light'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying to put results in a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this code is to start the document \n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Linear Regression', 0)\n",
    "\n",
    "p = document.add_paragraph('Here we are trying to find what will be the result of trying diffent combinations of features. ')\n",
    "\n",
    "# p.add_run('bold').bold = True\n",
    "# p.add_run(' and some ')\n",
    "# p.add_run('italic.').italic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "    reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    plt.show()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r2_score(df[to_find], y_pred))),\n",
    "    str(('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))),\n",
    "    str(('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred)))],style='List Bullet'\n",
    ")\n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first , second in itertools.combinations(options,2):\n",
    "    \n",
    "    document.add_heading(\"{} {}\".format(first, second), level=1)\n",
    "#     print(first, second)\n",
    "\n",
    "    get_every_thing(first, second)\n",
    "    \n",
    "document.save('/Users/piyush2017/Downloads/LinearRegression.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _______________Don't touch it._____________________O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding table values together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this code is to start the document \n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Linear Regression', 0)\n",
    "\n",
    "p = document.add_paragraph('Here we are trying to find what will be the result of trying diffent combinations of features. ')\n",
    "\n",
    "# p.add_run('bold').bold = True\n",
    "# p.add_run(' and some ')\n",
    "# p.add_run('italic.').italic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "    reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    plt.show()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    \n",
    "    r2 = r2_score(df[to_find], y_pred)\n",
    "    mse = mean_squared_error(df[to_find], y_pred)\n",
    "    mae = mean_absolute_error(df[to_find], y_pred)\n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r2)),\n",
    "    str(('MSE: %.3f' % mse)),\n",
    "    str(('MAE: %.3f' % mae))],style='List Bullet'\n",
    ")\n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first , second in itertools.combinations(options,2):\n",
    "    \n",
    "    document.add_heading(\"{} {}\".format(first, second), level=1)\n",
    "#     print(first, second)\n",
    "\n",
    "    get_every_thing(first, second)\n",
    "\n",
    "print(r2, mse, mae, end='\\n')\n",
    "    \n",
    "document.save('/Users/piyush2017/Downloads/LinearRegression02.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============Don't touch it.================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = \"\"\"\n",
    "# R2:\n",
    "### r-squared\n",
    "The close to 1 it is the better then it says that the value us used for prediction is moving with the final value that you want.\n",
    "\n",
    "https://www.investopedia.com/terms/r/r-squared.asp\n",
    "\n",
    "# MSE: \n",
    "### mean squared error (MSE)\n",
    "It calulate the distace of value from the mean:\n",
    "\n",
    "An MSE of zero, meaning that the estimator <b> Z </b> predicts observations of the parameter <b> X </b>  with perfect accuracy, is the ideal, but is typically not possible.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "# MAE:\n",
    "### mean absolute error (MAE)\n",
    "\n",
    "It's basically the absolute error |x-x| so lower the value the better \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this code is to start the document \n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Linear Regression', 0)\n",
    "\n",
    "p = document.add_paragraph('Here we are trying to find what will be the result of trying diffent combinations of features. ')\n",
    "\n",
    "# p.add_run('bold').bold = True\n",
    "# p.add_run(' and some ')\n",
    "# p.add_run('italic.').italic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "    reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(df[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(df[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(df[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    \n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "    )\n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = []\n",
    "mse = []\n",
    "mae = []\n",
    "par = []\n",
    "\n",
    "\n",
    "for first , second in itertools.combinations(options,2):\n",
    "    \n",
    "    document.add_heading(\"{} {}\".format(first, second), level=1)\n",
    "#     print(first, second)\n",
    "    par.append(\"{} {}\".format(first, second))\n",
    "    get_every_thing(first, second)\n",
    "\n",
    "document.add_page_break()\n",
    "table = document.add_table(rows=1, cols=4)\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'Pair'\n",
    "hdr_cells[1].text = 'R2'\n",
    "hdr_cells[2].text = 'MSE'\n",
    "hdr_cells[3].text = 'MAE'\n",
    "\n",
    "for i in range(len(r2)):\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = str(par[i])\n",
    "    row_cells[1].text = r2[i]\n",
    "    row_cells[2].text = mse[i]\n",
    "    row_cells[3].text = mae[i]\n",
    "    print(str(par[i]), str(r2[i]),str(mse[i]),str(mae[i]))\n",
    "    \n",
    "document.add_paragraph(theory)\n",
    "    \n",
    "print(r2, mse, mae, end='\\n')\n",
    "    \n",
    "document.save('/Users/piyush2017/Downloads/LinearRegression03.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = [(\"LinearRegression\",LinearRegression()), (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============Don't touch it.================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = \"\"\"\n",
    "# R2:\n",
    "### r-squared\n",
    "The close to 1 it is the better then it says that the value us used for prediction is moving with the final value that you want.\n",
    "\n",
    "https://www.investopedia.com/terms/r/r-squared.asp\n",
    "\n",
    "# MSE: \n",
    "### mean squared error (MSE)\n",
    "It calulate the distace of value from the mean:\n",
    "\n",
    "An MSE of zero, meaning that the estimator <b> Z </b> predicts observations of the parameter <b> X </b>  with perfect accuracy, is the ideal, but is typically not possible.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "# MAE:\n",
    "### mean absolute error (MAE)\n",
    "\n",
    "It's basically the absolute error |x-x| so lower the value the better \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/scaled_datatrainingcopy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this code is to start the document \n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Linear Regression', 0)\n",
    "\n",
    "p = document.add_paragraph('Here we are trying to find what will be the result of trying diffent combinations of features. ')\n",
    "\n",
    "# p.add_run('bold').bold = True\n",
    "# p.add_run(' and some ')\n",
    "# p.add_run('italic.').italic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = [(\"LinearRegression\",LinearRegression()), (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "#     reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(df[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(df[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(df[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    \n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "    )\n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for name, reg in reg:\n",
    "    r2 = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    par = []\n",
    "    \n",
    "    document.add_heading(\"Here are the results of {}\".format(name), level=2)\n",
    "    \n",
    "    for first , second in itertools.combinations(options,2):\n",
    "\n",
    "        document.add_heading(\"{} {}\".format(first, second), level=1)\n",
    "    #     print(first, second)\n",
    "        par.append(\"{} {}\".format(first, second))\n",
    "        get_every_thing(first, second)\n",
    "\n",
    "    document.add_page_break()\n",
    "    table = document.add_table(rows=1, cols=4)\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Pair'\n",
    "    hdr_cells[1].text = 'R2'\n",
    "    hdr_cells[2].text = 'MSE'\n",
    "    hdr_cells[3].text = 'MAE'\n",
    "\n",
    "    for i in range(len(r2)):\n",
    "        row_cells = table.add_row().cells\n",
    "        row_cells[0].text = str(par[i])\n",
    "        row_cells[1].text = r2[i]\n",
    "        row_cells[2].text = mse[i]\n",
    "        row_cells[3].text = mae[i]\n",
    "        print(str(par[i]), str(r2[i]),str(mse[i]),str(mae[i]))\n",
    "\n",
    "    document.add_paragraph(theory)\n",
    "\n",
    "    print(r2, mse, mae, end='\\n')\n",
    "    \n",
    "document.save('/Users/piyush2017/Downloads/LinearRegression05.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============Don't touch it.===all three data sets=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Temperature', 'Humidity', 'Light','CO2', 'HumidityRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/jupyter_notebooks/data/scaled_datatrainingcopy.csv')\n",
    "ts1 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/jupyter_notebooks/data/scaled_datatestcopy.csv')\n",
    "ts2 = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/jupyter_notebooks/data/scaled_datatest2copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theory = \"\"\"\n",
    "# R2:\n",
    "### r-squared\n",
    "The close to 1 it is the better then it says that the value us used for prediction is moving with the final value that you want.\n",
    "\n",
    "https://www.investopedia.com/terms/r/r-squared.asp\n",
    "\n",
    "# MSE: \n",
    "### mean squared error (MSE)\n",
    "It calulate the distace of value from the mean:\n",
    "\n",
    "An MSE of zero, meaning that the estimator <b> Z </b> predicts observations of the parameter <b> X </b>  with perfect accuracy, is the ideal, but is typically not possible.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "\n",
    "# MAE:\n",
    "### mean absolute error (MAE)\n",
    "\n",
    "It's basically the absolute error |x-x| so lower the value the better \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all this code is to start the document \n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Linear Regression', 0)\n",
    "\n",
    "p = document.add_paragraph('Here we are trying to find what will be the result of trying diffent combinations of features. ')\n",
    "\n",
    "# p.add_run('bold').bold = True\n",
    "# p.add_run(' and some ')\n",
    "# p.add_run('italic.').italic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = []\n",
    "mse = []\n",
    "mae = []\n",
    "par = []\n",
    "\n",
    "def get_every_thing(to_use, to_find):\n",
    "#     reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(df[to_use], df[to_find])\n",
    "    plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(df[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(df[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(df[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    \n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "    )\n",
    "    \n",
    "    #----------------------For two test sets------------------------------\n",
    "    \n",
    "    y_pred = reg.predict(ts1[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(ts1[to_use], ts1[to_find])\n",
    "    plt.plot(ts1[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(ts1[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(ts1[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(ts1[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    \n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet')\n",
    "    \n",
    "    \n",
    "    y_pred = reg.predict(ts2[[to_use]])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.style.context('ggplot')\n",
    "    plt.xlabel(to_use)\n",
    "    plt.ylabel(to_find)\n",
    "    plt.scatter(ts2[to_use], ts2[to_find])\n",
    "    plt.plot(ts2[[to_use]], y_pred, color = 'black')\n",
    "    plt.savefig('monty-truth.png')\n",
    "    #plt.show()\n",
    "    #plt.clf() https://stackoverflow.com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib\n",
    "    plt.close()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(ts2[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(ts2[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(ts2[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    \n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "    )\n",
    "    \n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = [(\"LinearRegression\",LinearRegression())]#, (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for name, reg in reg:\n",
    "#     r2 = []\n",
    "#     mse = []\n",
    "#     mae = []\n",
    "#     par = []\n",
    "    \n",
    "    document.add_heading(\"Here are the results of {}\".format(name), level=2)\n",
    "    \n",
    "    for first , second in itertools.combinations(options,2):\n",
    "\n",
    "        document.add_heading(\"{} {}\".format(first, second), level=1)\n",
    "    #     print(first, second)\n",
    "        par.append(\"{} {}\".format(first, second))\n",
    "        get_every_thing(first, second)\n",
    "\n",
    "    document.add_page_break()\n",
    "    table = document.add_table(rows=1, cols=4)\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Pair'\n",
    "    hdr_cells[1].text = 'R2'\n",
    "    hdr_cells[2].text = 'MSE'\n",
    "    hdr_cells[3].text = 'MAE'\n",
    "\n",
    "#     for i in range(len(r2)):\n",
    "#         row_cells = table.add_row().cells\n",
    "#         row_cells[0].text = str(par[i])\n",
    "#         row_cells[1].text = r2[i]\n",
    "#         row_cells[2].text = mse[i]\n",
    "#         row_cells[3].text = mae[i]\n",
    "#         print(str(par[i]), str(r2[i]),str(mse[i]),str(mae[i]))\n",
    "\n",
    "    document.add_paragraph(theory)\n",
    "\n",
    "    print(r2, mse, mae, end='\\n')\n",
    "    \n",
    "document.save('/Users/piyush2017/Downloads/LinearRegression07.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2df = pd.DataFrame(r2)\n",
    "msedf = pd.DataFrame(mse)\n",
    "maedf = pd.DataFrame(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure = pd.concat([r2df, msedf, maedf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure.to_csv('linear_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = [(\"LinearRegression\",LinearRegression())]#, (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_every_thing(to_use, to_find):\n",
    "    \n",
    "    r2 = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    par = []\n",
    "#     reg = LinearRegression() \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    y_pred = reg.predict(df[[to_use]])\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.style.context('ggplot')\n",
    "#     plt.xlabel(to_use)\n",
    "#     plt.ylabel(to_find)\n",
    "#     plt.scatter(df[to_use], df[to_find])\n",
    "#     plt.plot(df[[to_use]], y_pred, color = 'black')\n",
    "#     plt.savefig('monty-truth.png')\n",
    "#     #plt.show()\n",
    "#     plt.clf()\n",
    "    \n",
    "#     document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(df[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(df[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(df[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    par.append(str(to_use+ \"/\" to_find))\n",
    "    \n",
    "    \n",
    "    document.add_paragraph(\n",
    "    [str(('R2: %.3f' % r)),\n",
    "    str(('MSE: %.3f' % s)),\n",
    "    str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "    )\n",
    "    \n",
    "    #----------------------For two test sets------------------------------\n",
    "    \n",
    "    y_pred = reg.predict(ts1[[to_use]])\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.style.context('ggplot')\n",
    "#     plt.xlabel(to_use)\n",
    "#     plt.ylabel(to_find)\n",
    "#     plt.scatter(ts1[to_use], ts1[to_find])\n",
    "#     plt.plot(ts1[[to_use]], y_pred, color = 'black')\n",
    "#     plt.savefig('monty-truth.png')\n",
    "#     #plt.show()\n",
    "#     plt.clf()\n",
    "    \n",
    "    document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(ts1[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(ts1[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(ts1[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    par.append(str(to_use+ \"/\" to_find))\n",
    "    \n",
    "    \n",
    "#     document.add_paragraph(\n",
    "#     [str(('R2: %.3f' % r)),\n",
    "#     str(('MSE: %.3f' % s)),\n",
    "#     str(('MAE: %.3f' % a))],style='List Bullet')\n",
    "    \n",
    "    \n",
    "    y_pred = reg.predict(ts2[[to_use]])\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.style.context('ggplot')\n",
    "#     plt.xlabel(to_use)\n",
    "#     plt.ylabel(to_find)\n",
    "#     plt.scatter(ts2[to_use], ts2[to_find])\n",
    "#     plt.plot(ts2[[to_use]], y_pred, color = 'black')\n",
    "#     plt.savefig('monty-truth.png')\n",
    "#     #plt.show()\n",
    "#     #plt.clf() https://stackoverflow.com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib\n",
    "#     plt.close()\n",
    "    \n",
    "#     document.add_picture('monty-truth.png', width=Inches(4))\n",
    "    \n",
    "    \n",
    "    # to get the numerical attribute\n",
    "    r = round(r2_score(ts2[to_find], y_pred), ndigits=3)\n",
    "    s = round(mean_squared_error(ts2[to_find], y_pred), ndigits=3)\n",
    "    a = round(mean_absolute_error(ts2[to_find], y_pred))\n",
    "    \n",
    "    r2.append(str(r))\n",
    "    mse.append(str(s))\n",
    "    mae.append(str(a))\n",
    "    par.append(str(to_use+ \"/\" to_find))\n",
    "    \n",
    "    \n",
    "    r2df = pd.DataFrame(r2)\n",
    "    msedf = pd.DataFrame(mse)\n",
    "    maedf = pd.DataFrame(mae)\n",
    "    pardf = pd.DataFrame(par)\n",
    "    \n",
    "    result_measure = pd.concat([par,r2df, msedf, maedf], axis=1)\n",
    "    \n",
    "    \n",
    "#     document.add_paragraph(\n",
    "#     [str(('R2: %.3f' % r)),\n",
    "#     str(('MSE: %.3f' % s)),\n",
    "#     str(('MAE: %.3f' % a))],style='List Bullet'\n",
    "#     )\n",
    "    \n",
    "\n",
    "#     document.add_page_break()\n",
    "    \n",
    "#     print('R2: %.3f' % r2_score(df[to_find], y_pred))\n",
    "#     print('MSE: %.3f' % mean_squared_error(df[to_find], y_pred))\n",
    "#     print('MAE: %.3f' % mean_absolute_error(df[to_find], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting result for all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Temperature', 'Humidity', 'Light','CO2', 'HumidityRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading all the data\n",
    "df = pd.read_csv('./data/scaled_datatrainingcopy.csv')\n",
    "ts1 = pd.read_csv('./data/scaled_datatestcopy.csv')\n",
    "ts2 = pd.read_csv('./data/scaled_datatest2copy.csv')\n",
    "\n",
    "data_sets = [df, ts1, ts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_every_thing(to_use, to_find):\n",
    "    \n",
    "    \n",
    "    reg.fit(df[[to_use]], df[to_find])\n",
    "    \n",
    "    for i in data_sets:\n",
    "        y_pred = reg.predict(i[[to_use]])\n",
    "\n",
    "        # to get the numerical attribute\n",
    "        r = round(r2_score(i[to_find], y_pred), ndigits=3)\n",
    "        s = round(mean_squared_error(i[to_find], y_pred), ndigits=3)\n",
    "        a = round(mean_absolute_error(i[to_find], y_pred))\n",
    "\n",
    "        r2.append(str(r))\n",
    "        mse.append(str(s))\n",
    "        mae.append(str(a))\n",
    "        par.append(str(to_use + to_find))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error #this are need to get the results\n",
    "reg = [(\"Lasso\",Lasso())]#, (\"Lasso\", Lasso()), (\"Ridge\",Ridge())]\n",
    "\n",
    "\n",
    "r2 = []\n",
    "mse = []\n",
    "mae = []\n",
    "par = []\n",
    "\n",
    "for name, reg in reg:    \n",
    "    for first , second in itertools.combinations(options,2):\n",
    "        get_every_thing(first, second)\n",
    "\n",
    "r2df = pd.DataFrame(r2)\n",
    "msedf = pd.DataFrame(mse)\n",
    "maedf = pd.DataFrame(mae)\n",
    "pardf = pd.DataFrame(par)\n",
    "\n",
    "result_measure = pd.concat([pardf,r2df, msedf, maedf], axis=1)\n",
    "\n",
    "result_measure.to_csv('/Users/piyush2017/Desktop/line04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TemperatureHumidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TemperatureHumidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TemperatureHumidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TemperatureLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TemperatureLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TemperatureLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TemperatureCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TemperatureCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TemperatureCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TemperatureHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TemperatureHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TemperatureHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HumidityLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HumidityLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HumidityLight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HumidityCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HumidityCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HumidityCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HumidityHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HumidityHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HumidityHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LightHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LightHumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CO2HumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CO2HumidityRatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CO2HumidityRatio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0        TemperatureHumidity\n",
       "1        TemperatureHumidity\n",
       "2        TemperatureHumidity\n",
       "3           TemperatureLight\n",
       "4           TemperatureLight\n",
       "5           TemperatureLight\n",
       "6             TemperatureCO2\n",
       "7             TemperatureCO2\n",
       "8             TemperatureCO2\n",
       "9   TemperatureHumidityRatio\n",
       "10  TemperatureHumidityRatio\n",
       "11  TemperatureHumidityRatio\n",
       "12             HumidityLight\n",
       "13             HumidityLight\n",
       "14             HumidityLight\n",
       "15               HumidityCO2\n",
       "16               HumidityCO2\n",
       "17               HumidityCO2\n",
       "18     HumidityHumidityRatio\n",
       "19     HumidityHumidityRatio\n",
       "20     HumidityHumidityRatio\n",
       "21                  LightCO2\n",
       "22                  LightCO2\n",
       "23                  LightCO2\n",
       "24        LightHumidityRatio\n",
       "25        LightHumidityRatio\n",
       "26        LightHumidityRatio\n",
       "27          CO2HumidityRatio\n",
       "28          CO2HumidityRatio\n",
       "29          CO2HumidityRatio"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pardf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TemperatureHumidity',\n",
       " 'TemperatureHumidity',\n",
       " 'TemperatureHumidity',\n",
       " 'TemperatureLight',\n",
       " 'TemperatureLight',\n",
       " 'TemperatureLight',\n",
       " 'TemperatureCO2',\n",
       " 'TemperatureCO2',\n",
       " 'TemperatureCO2',\n",
       " 'TemperatureHumidityRatio',\n",
       " 'TemperatureHumidityRatio',\n",
       " 'TemperatureHumidityRatio',\n",
       " 'HumidityLight',\n",
       " 'HumidityLight',\n",
       " 'HumidityLight',\n",
       " 'HumidityCO2',\n",
       " 'HumidityCO2',\n",
       " 'HumidityCO2',\n",
       " 'HumidityHumidityRatio',\n",
       " 'HumidityHumidityRatio',\n",
       " 'HumidityHumidityRatio',\n",
       " 'LightCO2',\n",
       " 'LightCO2',\n",
       " 'LightCO2',\n",
       " 'LightHumidityRatio',\n",
       " 'LightHumidityRatio',\n",
       " 'LightHumidityRatio',\n",
       " 'CO2HumidityRatio',\n",
       " 'CO2HumidityRatio',\n",
       " 'CO2HumidityRatio']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2df = pd.DataFrame(r2)\n",
    "msedf = pd.DataFrame(mse)\n",
    "maedf = pd.DataFrame(mae)\n",
    "pardf = pd.DataFrame(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure = pd.concat([par,r2df, msedf, maedf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure.to_csv('/Users/piyush2017/Downloads/linear_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
