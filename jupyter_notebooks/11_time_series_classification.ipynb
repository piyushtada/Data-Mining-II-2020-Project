{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Riccardo Guidotti](http://kdd.isti.cnr.it/people/riccardo-guidotti)  \n",
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import make_cylinder_bell_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_cylinder_bell_funnel(n_samples=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i, classe in enumerate(['cylinder', 'bell', 'funnel']):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    for x in X[y == i]:\n",
    "        plt.plot(x, color='C0', linewidth=0.9)\n",
    "    plt.title('Class: {}'.format(classe), fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "from tslearn.shapelets import ShapeletModel\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X = scaler.fit_transform(X).reshape(X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ts 700\n",
      "ts_sz 128\n",
      "n_classes 3\n",
      "shapelet_sizes {12: 5}\n"
     ]
    }
   ],
   "source": [
    "n_ts, ts_sz = X_train.shape\n",
    "n_classes = len(set(y))\n",
    "\n",
    "# Set the number of shapelets per size as done in the original paper\n",
    "shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                       ts_sz=ts_sz,\n",
    "                                                       n_classes=n_classes,\n",
    "                                                       l=0.1,\n",
    "                                                       r=1)\n",
    "\n",
    "print('n_ts', n_ts)\n",
    "print('ts_sz', ts_sz)\n",
    "print('n_classes', n_classes)\n",
    "print('shapelet_sizes', shapelet_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model using parameters provided by the authors (except that we use\n",
    "# fewer iterations here)\n",
    "shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                        optimizer=\"sgd\",\n",
    "                        weight_regularizer=.01,\n",
    "                        max_iter=200,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/200\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.1601 - categorical_accuracy: 0.3200 - categorical_crossentropy: 1.1058\n",
      "Epoch 2/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1600 - categorical_accuracy: 0.3100 - categorical_crossentropy: 1.1058\n",
      "Epoch 3/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1599 - categorical_accuracy: 0.3200 - categorical_crossentropy: 1.1057\n",
      "Epoch 4/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1598 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1057\n",
      "Epoch 5/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1597 - categorical_accuracy: 0.3257 - categorical_crossentropy: 1.1057\n",
      "Epoch 6/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1596 - categorical_accuracy: 0.3257 - categorical_crossentropy: 1.1056\n",
      "Epoch 7/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1596 - categorical_accuracy: 0.3243 - categorical_crossentropy: 1.1056\n",
      "Epoch 8/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1595 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1056\n",
      "Epoch 9/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1594 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1056\n",
      "Epoch 10/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1593 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1055\n",
      "Epoch 11/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1592 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1055\n",
      "Epoch 12/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1591 - categorical_accuracy: 0.3257 - categorical_crossentropy: 1.1055\n",
      "Epoch 13/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1590 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1055\n",
      "Epoch 14/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1589 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1054\n",
      "Epoch 15/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1588 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1054\n",
      "Epoch 16/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1587 - categorical_accuracy: 0.3271 - categorical_crossentropy: 1.1054\n",
      "Epoch 17/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1586 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1053\n",
      "Epoch 18/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1585 - categorical_accuracy: 0.3243 - categorical_crossentropy: 1.1053\n",
      "Epoch 19/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1584 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1053\n",
      "Epoch 20/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1583 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1053\n",
      "Epoch 21/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1582 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1052\n",
      "Epoch 22/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1581 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1052\n",
      "Epoch 23/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1580 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1052\n",
      "Epoch 24/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1579 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1052\n",
      "Epoch 25/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1578 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1051\n",
      "Epoch 26/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1578 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1051\n",
      "Epoch 27/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1577 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1051\n",
      "Epoch 28/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1576 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1051\n",
      "Epoch 29/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1575 - categorical_accuracy: 0.3400 - categorical_crossentropy: 1.1050\n",
      "Epoch 30/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1574 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1050\n",
      "Epoch 31/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1573 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1050\n",
      "Epoch 32/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1572 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1050\n",
      "Epoch 33/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1571 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1049\n",
      "Epoch 34/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1570 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1049\n",
      "Epoch 35/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1569 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1049\n",
      "Epoch 36/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1569 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1049\n",
      "Epoch 37/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1568 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1049\n",
      "Epoch 38/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1567 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1048\n",
      "Epoch 39/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1566 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1048\n",
      "Epoch 40/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1565 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1048\n",
      "Epoch 41/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1564 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1048\n",
      "Epoch 42/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1563 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1047\n",
      "Epoch 43/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1562 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1047\n",
      "Epoch 44/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1561 - categorical_accuracy: 0.3414 - categorical_crossentropy: 1.1047\n",
      "Epoch 45/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1561 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1047\n",
      "Epoch 46/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1560 - categorical_accuracy: 0.3414 - categorical_crossentropy: 1.1046\n",
      "Epoch 47/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1559 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1046\n",
      "Epoch 48/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1558 - categorical_accuracy: 0.3400 - categorical_crossentropy: 1.1046\n",
      "Epoch 49/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1557 - categorical_accuracy: 0.3400 - categorical_crossentropy: 1.1046\n",
      "Epoch 50/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1556 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1046\n",
      "Epoch 51/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1555 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1045\n",
      "Epoch 52/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1554 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1045\n",
      "Epoch 53/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1554 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1045\n",
      "Epoch 54/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1553 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1045\n",
      "Epoch 55/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1552 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1045\n",
      "Epoch 56/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1551 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1044\n",
      "Epoch 57/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1550 - categorical_accuracy: 0.3443 - categorical_crossentropy: 1.1044\n",
      "Epoch 58/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1549 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1044\n",
      "Epoch 59/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1548 - categorical_accuracy: 0.3486 - categorical_crossentropy: 1.1044\n",
      "Epoch 60/200\n",
      "700/700 [==============================] - 0s 20us/step - loss: 1.1548 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1044\n",
      "Epoch 61/200\n",
      "700/700 [==============================] - 0s 24us/step - loss: 1.1547 - categorical_accuracy: 0.3486 - categorical_crossentropy: 1.1043\n",
      "Epoch 62/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1546 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1043\n",
      "Epoch 63/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1545 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1043\n",
      "Epoch 64/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1544 - categorical_accuracy: 0.3486 - categorical_crossentropy: 1.1043\n",
      "Epoch 65/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1543 - categorical_accuracy: 0.3471 - categorical_crossentropy: 1.1042\n",
      "Epoch 66/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1543 - categorical_accuracy: 0.3514 - categorical_crossentropy: 1.1042\n",
      "Epoch 67/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1542 - categorical_accuracy: 0.3443 - categorical_crossentropy: 1.1042\n",
      "Epoch 68/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1541 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1042\n",
      "Epoch 69/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1540 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1042\n",
      "Epoch 70/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1539 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1042\n",
      "Epoch 71/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1538 - categorical_accuracy: 0.3443 - categorical_crossentropy: 1.1041\n",
      "Epoch 72/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1538 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1041\n",
      "Epoch 73/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1537 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1041\n",
      "Epoch 74/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1536 - categorical_accuracy: 0.3414 - categorical_crossentropy: 1.1041\n",
      "Epoch 75/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1535 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1041\n",
      "Epoch 76/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1534 - categorical_accuracy: 0.3471 - categorical_crossentropy: 1.1040\n",
      "Epoch 77/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1534 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1040\n",
      "Epoch 78/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1533 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1040\n",
      "Epoch 79/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1532 - categorical_accuracy: 0.3443 - categorical_crossentropy: 1.1040\n",
      "Epoch 80/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1531 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1040\n",
      "Epoch 81/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1530 - categorical_accuracy: 0.3457 - categorical_crossentropy: 1.1039\n",
      "Epoch 82/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1529 - categorical_accuracy: 0.3343 - categorical_crossentropy: 1.1039\n",
      "Epoch 83/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1529 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1039\n",
      "Epoch 84/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1528 - categorical_accuracy: 0.3314 - categorical_crossentropy: 1.1039\n",
      "Epoch 85/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1527 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1038\n",
      "Epoch 86/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1526 - categorical_accuracy: 0.3400 - categorical_crossentropy: 1.1038\n",
      "Epoch 87/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1525 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1038\n",
      "Epoch 88/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1524 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1038\n",
      "Epoch 89/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1524 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1038\n",
      "Epoch 90/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1523 - categorical_accuracy: 0.3357 - categorical_crossentropy: 1.1038\n",
      "Epoch 91/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1522 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1037\n",
      "Epoch 92/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1521 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1037\n",
      "Epoch 93/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1521 - categorical_accuracy: 0.3429 - categorical_crossentropy: 1.1037\n",
      "Epoch 94/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1520 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1037\n",
      "Epoch 95/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1519 - categorical_accuracy: 0.3400 - categorical_crossentropy: 1.1037\n",
      "Epoch 96/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1518 - categorical_accuracy: 0.3371 - categorical_crossentropy: 1.1036\n",
      "Epoch 97/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1517 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1036\n",
      "Epoch 98/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1517 - categorical_accuracy: 0.3271 - categorical_crossentropy: 1.1036\n",
      "Epoch 99/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1516 - categorical_accuracy: 0.3286 - categorical_crossentropy: 1.1036\n",
      "Epoch 100/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1515 - categorical_accuracy: 0.3329 - categorical_crossentropy: 1.1036\n",
      "Epoch 101/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1514 - categorical_accuracy: 0.3386 - categorical_crossentropy: 1.1035\n",
      "Epoch 102/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1513 - categorical_accuracy: 0.3300 - categorical_crossentropy: 1.1035\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 13us/step - loss: 1.1513 - categorical_accuracy: 0.3186 - categorical_crossentropy: 1.1035\n",
      "Epoch 104/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1512 - categorical_accuracy: 0.3157 - categorical_crossentropy: 1.1035\n",
      "Epoch 105/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1511 - categorical_accuracy: 0.3171 - categorical_crossentropy: 1.1035\n",
      "Epoch 106/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1510 - categorical_accuracy: 0.3157 - categorical_crossentropy: 1.1035\n",
      "Epoch 107/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1509 - categorical_accuracy: 0.3100 - categorical_crossentropy: 1.1034\n",
      "Epoch 108/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1509 - categorical_accuracy: 0.3186 - categorical_crossentropy: 1.1034\n",
      "Epoch 109/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1508 - categorical_accuracy: 0.3014 - categorical_crossentropy: 1.1034\n",
      "Epoch 110/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1507 - categorical_accuracy: 0.2986 - categorical_crossentropy: 1.1034\n",
      "Epoch 111/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1506 - categorical_accuracy: 0.3014 - categorical_crossentropy: 1.1034\n",
      "Epoch 112/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1506 - categorical_accuracy: 0.3000 - categorical_crossentropy: 1.1034\n",
      "Epoch 113/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1505 - categorical_accuracy: 0.2900 - categorical_crossentropy: 1.1033\n",
      "Epoch 114/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1504 - categorical_accuracy: 0.2986 - categorical_crossentropy: 1.1033\n",
      "Epoch 115/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1503 - categorical_accuracy: 0.2914 - categorical_crossentropy: 1.1033\n",
      "Epoch 116/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1503 - categorical_accuracy: 0.2743 - categorical_crossentropy: 1.1033\n",
      "Epoch 117/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1502 - categorical_accuracy: 0.2814 - categorical_crossentropy: 1.1033\n",
      "Epoch 118/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1501 - categorical_accuracy: 0.2657 - categorical_crossentropy: 1.1032\n",
      "Epoch 119/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1500 - categorical_accuracy: 0.2771 - categorical_crossentropy: 1.1032\n",
      "Epoch 120/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1499 - categorical_accuracy: 0.2729 - categorical_crossentropy: 1.1032\n",
      "Epoch 121/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1499 - categorical_accuracy: 0.2714 - categorical_crossentropy: 1.1032\n",
      "Epoch 122/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1498 - categorical_accuracy: 0.2686 - categorical_crossentropy: 1.1032\n",
      "Epoch 123/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1497 - categorical_accuracy: 0.2657 - categorical_crossentropy: 1.1032\n",
      "Epoch 124/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1496 - categorical_accuracy: 0.2557 - categorical_crossentropy: 1.1031\n",
      "Epoch 125/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1496 - categorical_accuracy: 0.2643 - categorical_crossentropy: 1.1031\n",
      "Epoch 126/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1495 - categorical_accuracy: 0.2571 - categorical_crossentropy: 1.1031\n",
      "Epoch 127/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1494 - categorical_accuracy: 0.2600 - categorical_crossentropy: 1.1031\n",
      "Epoch 128/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1493 - categorical_accuracy: 0.2514 - categorical_crossentropy: 1.1031\n",
      "Epoch 129/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1493 - categorical_accuracy: 0.2557 - categorical_crossentropy: 1.1031\n",
      "Epoch 130/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1492 - categorical_accuracy: 0.2557 - categorical_crossentropy: 1.1030\n",
      "Epoch 131/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1491 - categorical_accuracy: 0.2543 - categorical_crossentropy: 1.1030\n",
      "Epoch 132/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1490 - categorical_accuracy: 0.2586 - categorical_crossentropy: 1.1030\n",
      "Epoch 133/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1490 - categorical_accuracy: 0.2557 - categorical_crossentropy: 1.1030\n",
      "Epoch 134/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1489 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.1030\n",
      "Epoch 135/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1488 - categorical_accuracy: 0.2443 - categorical_crossentropy: 1.1030\n",
      "Epoch 136/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1487 - categorical_accuracy: 0.2557 - categorical_crossentropy: 1.1030\n",
      "Epoch 137/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1487 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.1029\n",
      "Epoch 138/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1486 - categorical_accuracy: 0.2500 - categorical_crossentropy: 1.1029\n",
      "Epoch 139/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1485 - categorical_accuracy: 0.2543 - categorical_crossentropy: 1.1029\n",
      "Epoch 140/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1484 - categorical_accuracy: 0.2386 - categorical_crossentropy: 1.1029\n",
      "Epoch 141/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1484 - categorical_accuracy: 0.2414 - categorical_crossentropy: 1.1029\n",
      "Epoch 142/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1483 - categorical_accuracy: 0.2357 - categorical_crossentropy: 1.1029\n",
      "Epoch 143/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1482 - categorical_accuracy: 0.2286 - categorical_crossentropy: 1.1028\n",
      "Epoch 144/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1482 - categorical_accuracy: 0.2271 - categorical_crossentropy: 1.1028\n",
      "Epoch 145/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1481 - categorical_accuracy: 0.2086 - categorical_crossentropy: 1.1028\n",
      "Epoch 146/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1480 - categorical_accuracy: 0.2329 - categorical_crossentropy: 1.1028\n",
      "Epoch 147/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1479 - categorical_accuracy: 0.2229 - categorical_crossentropy: 1.1028\n",
      "Epoch 148/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1479 - categorical_accuracy: 0.2186 - categorical_crossentropy: 1.1028\n",
      "Epoch 149/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1478 - categorical_accuracy: 0.2286 - categorical_crossentropy: 1.1027\n",
      "Epoch 150/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1477 - categorical_accuracy: 0.2257 - categorical_crossentropy: 1.1027\n",
      "Epoch 151/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1476 - categorical_accuracy: 0.2086 - categorical_crossentropy: 1.1027\n",
      "Epoch 152/200\n",
      "700/700 [==============================] - 0s 18us/step - loss: 1.1476 - categorical_accuracy: 0.2114 - categorical_crossentropy: 1.1027\n",
      "Epoch 153/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1475 - categorical_accuracy: 0.1943 - categorical_crossentropy: 1.1027\n",
      "Epoch 154/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1474 - categorical_accuracy: 0.2086 - categorical_crossentropy: 1.1027\n",
      "Epoch 155/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1474 - categorical_accuracy: 0.2086 - categorical_crossentropy: 1.1027\n",
      "Epoch 156/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1473 - categorical_accuracy: 0.2014 - categorical_crossentropy: 1.1026\n",
      "Epoch 157/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1472 - categorical_accuracy: 0.2171 - categorical_crossentropy: 1.1026\n",
      "Epoch 158/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1471 - categorical_accuracy: 0.2243 - categorical_crossentropy: 1.1026\n",
      "Epoch 159/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1471 - categorical_accuracy: 0.2086 - categorical_crossentropy: 1.1026\n",
      "Epoch 160/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1470 - categorical_accuracy: 0.2029 - categorical_crossentropy: 1.1026\n",
      "Epoch 161/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1469 - categorical_accuracy: 0.2100 - categorical_crossentropy: 1.1026\n",
      "Epoch 162/200\n",
      "700/700 [==============================] - 0s 19us/step - loss: 1.1469 - categorical_accuracy: 0.2057 - categorical_crossentropy: 1.1025\n",
      "Epoch 163/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1468 - categorical_accuracy: 0.1957 - categorical_crossentropy: 1.1025\n",
      "Epoch 164/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1467 - categorical_accuracy: 0.2014 - categorical_crossentropy: 1.1025\n",
      "Epoch 165/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1467 - categorical_accuracy: 0.1943 - categorical_crossentropy: 1.1025\n",
      "Epoch 166/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1466 - categorical_accuracy: 0.1857 - categorical_crossentropy: 1.1025\n",
      "Epoch 167/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1465 - categorical_accuracy: 0.1957 - categorical_crossentropy: 1.1025\n",
      "Epoch 168/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1464 - categorical_accuracy: 0.1857 - categorical_crossentropy: 1.1024\n",
      "Epoch 169/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1464 - categorical_accuracy: 0.1886 - categorical_crossentropy: 1.1024\n",
      "Epoch 170/200\n",
      "700/700 [==============================] - 0s 18us/step - loss: 1.1463 - categorical_accuracy: 0.1900 - categorical_crossentropy: 1.1024\n",
      "Epoch 171/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1462 - categorical_accuracy: 0.1871 - categorical_crossentropy: 1.1024\n",
      "Epoch 172/200\n",
      "700/700 [==============================] - 0s 17us/step - loss: 1.1462 - categorical_accuracy: 0.1814 - categorical_crossentropy: 1.1024\n",
      "Epoch 173/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1461 - categorical_accuracy: 0.1857 - categorical_crossentropy: 1.1024\n",
      "Epoch 174/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1460 - categorical_accuracy: 0.1843 - categorical_crossentropy: 1.1024\n",
      "Epoch 175/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1460 - categorical_accuracy: 0.1771 - categorical_crossentropy: 1.1024\n",
      "Epoch 176/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1459 - categorical_accuracy: 0.1829 - categorical_crossentropy: 1.1023\n",
      "Epoch 177/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1458 - categorical_accuracy: 0.1786 - categorical_crossentropy: 1.1023\n",
      "Epoch 178/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1457 - categorical_accuracy: 0.1786 - categorical_crossentropy: 1.1023\n",
      "Epoch 179/200\n",
      "700/700 [==============================] - 0s 13us/step - loss: 1.1457 - categorical_accuracy: 0.1800 - categorical_crossentropy: 1.1023\n",
      "Epoch 180/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1456 - categorical_accuracy: 0.1800 - categorical_crossentropy: 1.1023\n",
      "Epoch 181/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1455 - categorical_accuracy: 0.1757 - categorical_crossentropy: 1.1023\n",
      "Epoch 182/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1455 - categorical_accuracy: 0.1771 - categorical_crossentropy: 1.1022\n",
      "Epoch 183/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1454 - categorical_accuracy: 0.1814 - categorical_crossentropy: 1.1022\n",
      "Epoch 184/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1453 - categorical_accuracy: 0.1743 - categorical_crossentropy: 1.1022\n",
      "Epoch 185/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1453 - categorical_accuracy: 0.1729 - categorical_crossentropy: 1.1022\n",
      "Epoch 186/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1452 - categorical_accuracy: 0.1657 - categorical_crossentropy: 1.1022\n",
      "Epoch 187/200\n",
      "700/700 [==============================] - 0s 12us/step - loss: 1.1451 - categorical_accuracy: 0.1700 - categorical_crossentropy: 1.1022\n",
      "Epoch 188/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1451 - categorical_accuracy: 0.1771 - categorical_crossentropy: 1.1022\n",
      "Epoch 189/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1450 - categorical_accuracy: 0.1629 - categorical_crossentropy: 1.1021\n",
      "Epoch 190/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1449 - categorical_accuracy: 0.1686 - categorical_crossentropy: 1.1021\n",
      "Epoch 191/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1449 - categorical_accuracy: 0.1686 - categorical_crossentropy: 1.1021\n",
      "Epoch 192/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1448 - categorical_accuracy: 0.1643 - categorical_crossentropy: 1.1021\n",
      "Epoch 193/200\n",
      "700/700 [==============================] - 0s 14us/step - loss: 1.1447 - categorical_accuracy: 0.1657 - categorical_crossentropy: 1.1021\n",
      "Epoch 194/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1447 - categorical_accuracy: 0.1643 - categorical_crossentropy: 1.1021\n",
      "Epoch 195/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1446 - categorical_accuracy: 0.1614 - categorical_crossentropy: 1.1021\n",
      "Epoch 196/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1445 - categorical_accuracy: 0.1671 - categorical_crossentropy: 1.1021\n",
      "Epoch 197/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1445 - categorical_accuracy: 0.1614 - categorical_crossentropy: 1.1020\n",
      "Epoch 198/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1444 - categorical_accuracy: 0.1686 - categorical_crossentropy: 1.1020\n",
      "Epoch 199/200\n",
      "700/700 [==============================] - 0s 15us/step - loss: 1.1443 - categorical_accuracy: 0.1614 - categorical_crossentropy: 1.1020\n",
      "Epoch 200/200\n",
      "700/700 [==============================] - 0s 16us/step - loss: 1.1443 - categorical_accuracy: 0.1629 - categorical_crossentropy: 1.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeletModel(batch_size=256, max_iter=200, n_shapelets_per_size={12: 5},\n",
       "              optimizer='sgd', random_state=None, shapelet_length=0.15,\n",
       "              total_lengths=3, verbose=1, verbose_level=None,\n",
       "              weight_regularizer=0.01)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 103us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = shp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.12\n",
      "F1-score [0.05447471 0.31788079 0.05208333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.07      0.05       100\n",
      "           1       0.47      0.24      0.32       100\n",
      "           2       0.05      0.05      0.05       100\n",
      "\n",
      "    accuracy                           0.12       300\n",
      "   macro avg       0.19      0.12      0.14       300\n",
      "weighted avg       0.19      0.12      0.14       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet-distances-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 43us/step\n"
     ]
    }
   ],
   "source": [
    "X_train2 = shp_clf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00642236, 0.01045328, 0.03184402, 0.00556008, 0.00921067],\n",
       "       [0.00526969, 0.00396355, 0.04040583, 0.00768598, 0.011156  ],\n",
       "       [0.01017316, 0.00830499, 0.04240378, 0.01234547, 0.01212241],\n",
       "       ...,\n",
       "       [0.00514301, 0.01160882, 0.0261356 , 0.01025216, 0.04187443],\n",
       "       [0.01015361, 0.00490552, 0.03830056, 0.00912492, 0.01281242],\n",
       "       [0.01353542, 0.00951477, 0.01631339, 0.00850169, 0.01002848]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 10us/step\n"
     ]
    }
   ],
   "source": [
    "X_test2 = shp_clf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.73\n",
      "F1-score [0.99       0.62616822 0.56989247]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       100\n",
      "           1       0.59      0.67      0.63       100\n",
      "           2       0.62      0.53      0.57       100\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.69\n",
      "F1-score [0.96969697 0.57798165 0.52173913]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.53      0.63      0.58       100\n",
      "           2       0.57      0.48      0.52       100\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.69      0.69      0.69       300\n",
      "weighted avg       0.69      0.69      0.69       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(values):\n",
    "    features = {\n",
    "        'avg': np.mean(values),\n",
    "        'std': np.std(values),\n",
    "        'var': np.var(values),\n",
    "        'med': np.median(values),\n",
    "        '10p': np.percentile(values, 10),\n",
    "        '25p': np.percentile(values, 25),\n",
    "        '50p': np.percentile(values, 50),\n",
    "        '75p': np.percentile(values, 75),\n",
    "        '90p': np.percentile(values, 90),\n",
    "        'iqr': np.percentile(values, 75) - np.percentile(values, 25),\n",
    "        'cov': 1.0 * np.mean(values) / np.std(values),\n",
    "        'skw': stats.skew(values),\n",
    "        'kur': stats.kurtosis(values)\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = np.array([list(calculate_features(x).values()) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39859446,  0.23519191,  0.05531524, ...,  1.69476262,\n",
       "         0.36034213, -0.8842845 ],\n",
       "       [ 0.45011623,  0.21610026,  0.04669932, ...,  2.08290465,\n",
       "         0.32862626, -0.61767966],\n",
       "       [ 0.42219464,  0.22458385,  0.05043791, ...,  1.87989759,\n",
       "         0.27583263, -0.91630096],\n",
       "       ...,\n",
       "       [ 0.52655729,  0.28183322,  0.07942997, ...,  1.86832936,\n",
       "        -0.46340955, -1.14728378],\n",
       "       [ 0.45154156,  0.22410403,  0.05022261, ...,  2.0148748 ,\n",
       "         0.19409557, -0.63827757],\n",
       "       [ 0.44552984,  0.20088531,  0.04035491, ...,  2.21783187,\n",
       "         0.41476313, -0.20365056]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = np.array([list(calculate_features(x).values()) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6733333333333333\n",
      "F1-score [1.         0.45555556 0.55454545]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       0.51      0.41      0.46       100\n",
      "           2       0.51      0.61      0.55       100\n",
      "\n",
      "    accuracy                           0.67       300\n",
      "   macro avg       0.67      0.67      0.67       300\n",
      "weighted avg       0.67      0.67      0.67       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train3, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "           2       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9733333333333334\n",
      "F1-score [0.95918367 0.99       0.97058824]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       100\n",
      "           1       0.99      0.99      0.99       100\n",
      "           2       0.95      0.99      0.97       100\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.97      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.classification import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       100\n",
      "           2       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(metric='dtw_sakoechiba')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, Activation, Conv1D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  128\n",
      "N. LABELS:  3\n"
     ]
    }
   ],
   "source": [
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_simple_cnn(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 121, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 121, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 121, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 121, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 117, 32)           2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 117, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 117, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 117, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 115, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 115, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 115, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 115, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,587\n",
      "Trainable params: 9,363\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 140 samples\n",
      "Epoch 1/5\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 0.9407 - accuracy: 0.6089 - val_loss: 1.0650 - val_accuracy: 0.3357\n",
      "Epoch 2/5\n",
      "560/560 [==============================] - 0s 457us/step - loss: 0.7007 - accuracy: 0.8750 - val_loss: 1.0346 - val_accuracy: 0.3643\n",
      "Epoch 3/5\n",
      "560/560 [==============================] - 0s 490us/step - loss: 0.5671 - accuracy: 0.9179 - val_loss: 1.0371 - val_accuracy: 0.5929\n",
      "Epoch 4/5\n",
      "560/560 [==============================] - 0s 464us/step - loss: 0.4895 - accuracy: 0.9393 - val_loss: 1.0501 - val_accuracy: 0.4214\n",
      "Epoch 5/5\n",
      "560/560 [==============================] - 0s 463us/step - loss: 0.4054 - accuracy: 0.9536 - val_loss: 1.0500 - val_accuracy: 0.3357\n"
     ]
    }
   ],
   "source": [
    "history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.34\n",
      "F1-score [0.         0.50890585 0.03738318]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.34      1.00      0.51       100\n",
      "           2       0.29      0.02      0.04       100\n",
      "\n",
      "    accuracy                           0.34       300\n",
      "   macro avg       0.21      0.34      0.18       300\n",
      "weighted avg       0.21      0.34      0.18       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0486841090520223, 0.3400000035762787]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(n_timesteps, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = build_lstm(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 280,835\n",
      "Trainable params: 280,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560 samples, validate on 140 samples\n",
      "Epoch 1/10\n",
      "560/560 [==============================] - 0s 494us/step - loss: 0.3096 - accuracy: 0.9786 - val_loss: 1.0019 - val_accuracy: 0.4786\n",
      "Epoch 2/10\n",
      "560/560 [==============================] - 0s 483us/step - loss: 0.2031 - accuracy: 0.9982 - val_loss: 0.9529 - val_accuracy: 0.4857\n",
      "Epoch 3/10\n",
      "560/560 [==============================] - 0s 477us/step - loss: 0.1474 - accuracy: 0.9946 - val_loss: 0.8271 - val_accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "560/560 [==============================] - 0s 481us/step - loss: 0.1153 - accuracy: 0.9964 - val_loss: 0.6623 - val_accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "560/560 [==============================] - 0s 476us/step - loss: 0.0897 - accuracy: 0.9946 - val_loss: 0.5490 - val_accuracy: 0.9571\n",
      "Epoch 6/10\n",
      "560/560 [==============================] - 0s 449us/step - loss: 0.0679 - accuracy: 0.9964 - val_loss: 0.3763 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "560/560 [==============================] - 0s 468us/step - loss: 0.0645 - accuracy: 0.9964 - val_loss: 0.3197 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "560/560 [==============================] - 0s 455us/step - loss: 0.0634 - accuracy: 0.9964 - val_loss: 0.2139 - val_accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "560/560 [==============================] - 0s 452us/step - loss: 0.0481 - accuracy: 0.9964 - val_loss: 0.2339 - val_accuracy: 0.8714\n",
      "Epoch 10/10\n",
      "560/560 [==============================] - 0s 435us/step - loss: 0.0365 - accuracy: 0.9982 - val_loss: 0.1714 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "history_lstm = cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                       validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.  0.5 0. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.33      1.00      0.50       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.11      0.33      0.17       300\n",
      "weighted avg       0.11      0.33      0.17       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0984290631612141, 0.3333333432674408]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_basic_motions\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_basic_motions(return_X_y=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Standing', b'Standing', b'Standing', b'Standing', b'Standing',\n",
       "       b'Standing', b'Standing', b'Standing', b'Standing', b'Standing',\n",
       "       b'Running', b'Running', b'Running', b'Running', b'Running',\n",
       "       b'Running', b'Running', b'Running', b'Running', b'Running',\n",
       "       b'Walking', b'Walking', b'Walking', b'Walking', b'Walking',\n",
       "       b'Walking', b'Walking', b'Walking', b'Walking', b'Walking',\n",
       "       b'Badminton', b'Badminton', b'Badminton', b'Badminton',\n",
       "       b'Badminton', b'Badminton', b'Badminton', b'Badminton',\n",
       "       b'Badminton', b'Badminton'], dtype='|S12')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(40, 100, 6)\n",
    "X_test = X_test.reshape(40, 100, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  100\n",
      "N. LABELS:  4\n",
      "N. FEATURES:  6\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2] \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "print(\"N. FEATURES: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm2(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(4, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = build_lstm2(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100, 4)            176       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 100,708\n",
      "Trainable params: 99,404\n",
      "Non-trainable params: 1,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 1.6396 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 1.3807 - accuracy: 0.4062 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.4749 - accuracy: 0.2188 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4223 - accuracy: 0.2188 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.3451 - accuracy: 0.4062 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 1.4631 - accuracy: 0.2500 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4985 - accuracy: 0.2188 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3982 - accuracy: 0.3438 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3987 - accuracy: 0.3125 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.5110 - accuracy: 0.2812 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.2976 - accuracy: 0.4375 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.5131 - accuracy: 0.3438 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4397 - accuracy: 0.4688 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.3529 - accuracy: 0.3125 - val_loss: 1.3870 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4446 - accuracy: 0.3125 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.3606 - accuracy: 0.3125 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.2436 - accuracy: 0.3125 - val_loss: 1.3875 - val_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4079 - accuracy: 0.2812 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.2856 - accuracy: 0.3125 - val_loss: 1.3885 - val_accuracy: 0.2500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.4732 - accuracy: 0.2812 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.3294 - accuracy: 0.5312 - val_loss: 1.3897 - val_accuracy: 0.2500\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 1.2545 - accuracy: 0.4062 - val_loss: 1.3906 - val_accuracy: 0.2500\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.2595 - accuracy: 0.2500 - val_loss: 1.3913 - val_accuracy: 0.2500\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.2807 - accuracy: 0.3125 - val_loss: 1.3923 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.2815 - accuracy: 0.2500 - val_loss: 1.3929 - val_accuracy: 0.2500\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.3232 - accuracy: 0.3125 - val_loss: 1.3940 - val_accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.5695 - accuracy: 0.1875 - val_loss: 1.3953 - val_accuracy: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.2730 - accuracy: 0.3438 - val_loss: 1.3958 - val_accuracy: 0.2500\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.4051 - accuracy: 0.2812 - val_loss: 1.3969 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.3944 - accuracy: 0.3750 - val_loss: 1.3968 - val_accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.2970 - accuracy: 0.3125 - val_loss: 1.3969 - val_accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 1.3477 - accuracy: 0.4375 - val_loss: 1.3967 - val_accuracy: 0.2500\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.4630 - accuracy: 0.3125 - val_loss: 1.3967 - val_accuracy: 0.2500\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.1793 - accuracy: 0.3750 - val_loss: 1.3965 - val_accuracy: 0.2500\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3082 - accuracy: 0.3750 - val_loss: 1.3964 - val_accuracy: 0.2500\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 1.4891 - accuracy: 0.1875 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.2156 - accuracy: 0.3750 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3283 - accuracy: 0.4375 - val_loss: 1.3959 - val_accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.1527 - accuracy: 0.4688 - val_loss: 1.3961 - val_accuracy: 0.2500\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3443 - accuracy: 0.5000 - val_loss: 1.3959 - val_accuracy: 0.2500\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.2797 - accuracy: 0.3750 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.2660 - accuracy: 0.4062 - val_loss: 1.3964 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 1.4138 - accuracy: 0.3125 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 1.4468 - accuracy: 0.3125 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 1.3009 - accuracy: 0.3438 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.2730 - accuracy: 0.5000 - val_loss: 1.3968 - val_accuracy: 0.2500\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 1.1731 - accuracy: 0.4062 - val_loss: 1.3969 - val_accuracy: 0.2500\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 1.2492 - accuracy: 0.4375 - val_loss: 1.3967 - val_accuracy: 0.2500\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 1.1663 - accuracy: 0.4688 - val_loss: 1.3977 - val_accuracy: 0.2500\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 1.3673 - accuracy: 0.4062 - val_loss: 1.3955 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history_lstm2 = lstm2.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.25\n",
      "F1-score [0.  0.  0.  0.4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.25      1.00      0.40        10\n",
      "\n",
      "    accuracy                           0.25        40\n",
      "   macro avg       0.06      0.25      0.10        40\n",
      "weighted avg       0.06      0.25      0.10        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm2.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 6, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn2 = X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], X_train_cnn.shape[2], 1)\n",
    "X_val_cnn2 = X_val_cnn.reshape(X_val_cnn.shape[0], X_val_cnn.shape[1], X_val_cnn.shape[2], 1)\n",
    "X_test_cnn2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "X_train_cnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn2(n_timesteps, n_features, n_outputs):\n",
    "    input_shape = (n_timesteps, n_features, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ks1_first = 3\n",
    "    ks1_second = 3\n",
    "    \n",
    "    ks2_first = 4\n",
    "    ks2_second = 4\n",
    "    \n",
    "    model.add(Conv2D(filters=(3), \n",
    "                     kernel_size=(ks1_first, ks1_second),\n",
    "                     input_shape=input_shape, \n",
    "                     padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    for _ in range(2):\n",
    "        model.add(Conv2D(filters=(4), \n",
    "                     kernel_size= (ks2_first, ks2_second), \n",
    "                         padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))  \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(Dense(64 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "    for _ in range(3):\n",
    "        model.add(Dense(128 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(1024 , kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = build_cnn2(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 6, 3)         30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 100, 6, 3)         12        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 100, 6, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 100, 6, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 6, 4)         196       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 100, 6, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 6, 4)         260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 100, 6, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                153664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 350,870\n",
      "Trainable params: 347,520\n",
      "Non-trainable params: 3,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 1.8272 - accuracy: 0.1562 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6504 - accuracy: 0.3438 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.6615 - accuracy: 0.2812 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.7045 - accuracy: 0.2812 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.1631 - accuracy: 0.1875 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6088 - accuracy: 0.2188 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7161 - accuracy: 0.2812 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6336 - accuracy: 0.3438 - val_loss: 1.3875 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4444 - accuracy: 0.2812 - val_loss: 1.3882 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7097 - accuracy: 0.3750 - val_loss: 1.3884 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4574 - accuracy: 0.3750 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.8774 - accuracy: 0.2188 - val_loss: 1.3884 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.5676 - accuracy: 0.2812 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1729 - accuracy: 0.3438 - val_loss: 1.3897 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4196 - accuracy: 0.3750 - val_loss: 1.3903 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3558 - accuracy: 0.3125 - val_loss: 1.3913 - val_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.5615 - accuracy: 0.3438 - val_loss: 1.3929 - val_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4723 - accuracy: 0.2812 - val_loss: 1.3945 - val_accuracy: 0.2500\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4228 - accuracy: 0.2500 - val_loss: 1.3959 - val_accuracy: 0.2500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6014 - accuracy: 0.1562 - val_loss: 1.3948 - val_accuracy: 0.2500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3968 - accuracy: 0.3125 - val_loss: 1.3953 - val_accuracy: 0.2500\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4730 - accuracy: 0.3438 - val_loss: 1.3968 - val_accuracy: 0.2500\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4776 - accuracy: 0.2812 - val_loss: 1.3985 - val_accuracy: 0.2500\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3880 - accuracy: 0.3125 - val_loss: 1.3994 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3957 - accuracy: 0.3438 - val_loss: 1.4017 - val_accuracy: 0.2500\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3530 - accuracy: 0.3438 - val_loss: 1.4039 - val_accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.5212 - accuracy: 0.2500 - val_loss: 1.4042 - val_accuracy: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4691 - accuracy: 0.3750 - val_loss: 1.4024 - val_accuracy: 0.2500\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.5327 - accuracy: 0.1562 - val_loss: 1.4012 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4108 - accuracy: 0.2812 - val_loss: 1.3965 - val_accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3100 - accuracy: 0.2812 - val_loss: 1.3927 - val_accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4827 - accuracy: 0.2812 - val_loss: 1.3873 - val_accuracy: 0.2500\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4206 - accuracy: 0.5312 - val_loss: 1.3842 - val_accuracy: 0.2500\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4358 - accuracy: 0.1875 - val_loss: 1.3803 - val_accuracy: 0.2500\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4078 - accuracy: 0.4062 - val_loss: 1.3749 - val_accuracy: 0.2500\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3828 - accuracy: 0.4375 - val_loss: 1.3715 - val_accuracy: 0.2500\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3863 - accuracy: 0.4688 - val_loss: 1.3679 - val_accuracy: 0.2500\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1948 - accuracy: 0.3750 - val_loss: 1.3635 - val_accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.4415 - accuracy: 0.3125 - val_loss: 1.3606 - val_accuracy: 0.2500\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.3125 - val_loss: 1.3612 - val_accuracy: 0.2500\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3122 - accuracy: 0.4062 - val_loss: 1.3595 - val_accuracy: 0.2500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1783 - accuracy: 0.5625 - val_loss: 1.3552 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.5319 - accuracy: 0.5000 - val_loss: 1.3500 - val_accuracy: 0.3750\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2696 - accuracy: 0.5312 - val_loss: 1.3442 - val_accuracy: 0.3750\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1187 - accuracy: 0.4688 - val_loss: 1.3347 - val_accuracy: 0.3750\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0927 - accuracy: 0.5625 - val_loss: 1.3282 - val_accuracy: 0.3750\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.3168 - accuracy: 0.3750 - val_loss: 1.3186 - val_accuracy: 0.3750\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2313 - accuracy: 0.5625 - val_loss: 1.3058 - val_accuracy: 0.3750\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2542 - accuracy: 0.6250 - val_loss: 1.2985 - val_accuracy: 0.3750\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1461 - accuracy: 0.4375 - val_loss: 1.2980 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "history_cnn2 = cnn2.fit(X_train_cnn2, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn2, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.4\n",
      "F1-score [0.45454545 0.         0.75       0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       1.00      0.60      0.75        10\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.40        40\n",
      "   macro avg       0.32      0.40      0.30        40\n",
      "weighted avg       0.32      0.40      0.30        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn2.predict(X_test_cnn2), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn3(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = build_cnn3(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 93, 16)            784       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 93, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 89, 32)            2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 89, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 87, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 87, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 87, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 87, 64)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 10,292\n",
      "Trainable params: 10,068\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 1.4343 - accuracy: 0.2500 - val_loss: 1.3885 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3860 - accuracy: 0.2812 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3422 - accuracy: 0.2812 - val_loss: 1.3822 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.3020 - accuracy: 0.4062 - val_loss: 1.3811 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2780 - accuracy: 0.4375 - val_loss: 1.3802 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2428 - accuracy: 0.4375 - val_loss: 1.3804 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2198 - accuracy: 0.4688 - val_loss: 1.3798 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1464 - accuracy: 0.5938 - val_loss: 1.3791 - val_accuracy: 0.3750\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0697 - accuracy: 0.7188 - val_loss: 1.3778 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0818 - accuracy: 0.6562 - val_loss: 1.3767 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0874 - accuracy: 0.6562 - val_loss: 1.3734 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9054 - accuracy: 0.8438 - val_loss: 1.3693 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9326 - accuracy: 0.7500 - val_loss: 1.3625 - val_accuracy: 0.6250\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8309 - accuracy: 0.8750 - val_loss: 1.3550 - val_accuracy: 0.6250\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7892 - accuracy: 0.8750 - val_loss: 1.3440 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8413 - accuracy: 0.7812 - val_loss: 1.3328 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7660 - accuracy: 0.8125 - val_loss: 1.3188 - val_accuracy: 0.6250\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7846 - accuracy: 0.8125 - val_loss: 1.2973 - val_accuracy: 0.6250\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.8750 - val_loss: 1.2783 - val_accuracy: 0.6250\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.8750 - val_loss: 1.2593 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.9688 - val_loss: 1.2273 - val_accuracy: 0.6250\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.9062 - val_loss: 1.1912 - val_accuracy: 0.6250\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.9688 - val_loss: 1.1596 - val_accuracy: 0.6250\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.8438 - val_loss: 1.1349 - val_accuracy: 0.6250\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.8438 - val_loss: 1.1213 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.9375 - val_loss: 1.0962 - val_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.9375 - val_loss: 1.0408 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8750 - val_loss: 0.9920 - val_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.9375 - val_loss: 0.9457 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.9062 - val_loss: 0.9050 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.9375 - val_loss: 0.8623 - val_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.9062 - val_loss: 0.8375 - val_accuracy: 0.6250\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.9062 - val_loss: 0.8319 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.9062 - val_loss: 0.8456 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9688 - val_loss: 0.8310 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.9062 - val_loss: 0.8008 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 1.0000 - val_loss: 0.7833 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8750 - val_loss: 0.7612 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9688 - val_loss: 0.7423 - val_accuracy: 0.6250\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.6250\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8750 - val_loss: 0.7251 - val_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.9688 - val_loss: 0.7432 - val_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.9062 - val_loss: 0.7250 - val_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.9062 - val_loss: 0.6429 - val_accuracy: 0.8750\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9375 - val_loss: 0.6253 - val_accuracy: 0.6250\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.9062 - val_loss: 0.6614 - val_accuracy: 0.6250\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.9375 - val_loss: 0.7002 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "history_cnn3 = cnn3.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.75\n",
      "F1-score [0.57142857 0.76190476 0.72727273 0.86956522]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        10\n",
      "           1       0.73      0.80      0.76        10\n",
      "           2       0.67      0.80      0.73        10\n",
      "           3       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.79      0.75      0.73        40\n",
      "weighted avg       0.79      0.75      0.73        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn3.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyts.readthedocs.io/en/stable/generated/pyts.multivariate.classification.MultivariateClassifier.html#pyts.multivariate.classification.MultivariateClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
