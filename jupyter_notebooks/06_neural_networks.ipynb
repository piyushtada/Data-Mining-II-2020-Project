{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Week_day</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.518470</td>\n",
       "      <td>0.278526</td>\n",
       "      <td>1.573763</td>\n",
       "      <td>0.364948</td>\n",
       "      <td>1.091757</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.488967</td>\n",
       "      <td>0.277713</td>\n",
       "      <td>1.591735</td>\n",
       "      <td>0.341881</td>\n",
       "      <td>1.080555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.488967</td>\n",
       "      <td>0.273645</td>\n",
       "      <td>1.573763</td>\n",
       "      <td>0.340290</td>\n",
       "      <td>1.075889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.488967</td>\n",
       "      <td>0.265508</td>\n",
       "      <td>1.573763</td>\n",
       "      <td>0.323587</td>\n",
       "      <td>1.066555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.439796</td>\n",
       "      <td>0.265508</td>\n",
       "      <td>1.573763</td>\n",
       "      <td>0.311655</td>\n",
       "      <td>1.049523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity     Light       CO2  HumidityRatio  Week_day  \\\n",
       "0     2.518470  0.278526  1.573763  0.364948       1.091757         1   \n",
       "1     2.488967  0.277713  1.591735  0.341881       1.080555         1   \n",
       "2     2.488967  0.273645  1.573763  0.340290       1.075889         1   \n",
       "3     2.488967  0.265508  1.573763  0.323587       1.066555         1   \n",
       "4     2.439796  0.265508  1.573763  0.311655       1.049523         1   \n",
       "\n",
       "   Occupancy  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = \"Occupancy\"\n",
    "df = pd.read_csv('/Users/piyush2017/Code/2020_Data_Mining_Project_02/data_mining_2020_project_occupancy_detection/data/scaled_datatrainingcopy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in df.columns if col != class_name]\n",
    "X = df[attributes].values\n",
    "y = df[class_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "activation {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
    "Activation function for the hidden layer.\n",
    "* 'identity', no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* 'logistic', the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* 'tanh', the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* 'relu', the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
    "The solver for weight optimization.\n",
    "* 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
    "* 'sgd' refers to stochastic gradient descent.\n",
    "* 'adam' refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "The default solver 'adam' works pretty well on relatively large datasets (>= 1000 training samples) in terms of both training time and validation score. For small datasets, 'lbfgs' can converge faster and perform better.\n",
    "\n",
    "alpha float, default=0.0001\n",
    "L2 penalty (regularization term) parameter.\n",
    "\n",
    "batch_size int, default='auto'\n",
    "Size of minibatches for stochastic optimizers. If the solver is 'lbfgs', the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "learning_rate {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
    "Learning rate schedule for weight updates.\n",
    "*'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "*'invscaling' gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of *'power_t'. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "*'adaptive' keeps the learning rate constant to 'learning_rate_init' as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if 'early_stopping' is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd'.\n",
    "\n",
    "learning_rate_init double, default=0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "power_t double, default=0.5\n",
    "The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to 'invscaling'. Only used when solver='sgd'.\n",
    "\n",
    "max_iter int, default=200\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations. For stochastic solvers ('sgd', 'adam'), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "shuffle bool, default=True\n",
    "Whether to shuffle samples in each iteration. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "random_state int, RandomState instance or None, default=None\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "tol float, default=1e-4\n",
    "Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
    "\n",
    "verbose bool, default=False\n",
    "Whether to print progress messages to stdout.\n",
    "\n",
    "warm_start bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.\n",
    "\n",
    "momentum float, default=0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver='sgd'.\n",
    "\n",
    "early_stopping bool, default=False\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "validation_fraction float, default=0.1\n",
    "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True\n",
    "\n",
    "beta_1 float, default=0.9\n",
    "Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "beta_2 float, default=0.999\n",
    "Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "epsilon float, default=1e-8\n",
    "Value for numerical stability in adam. Only used when solver='adam'\n",
    "\n",
    "n_iter_no_change int, default=10\n",
    "Maximum number of epochs to not meet tol improvement. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "\n",
    "### Attributes\n",
    "loss_ float\n",
    "The current loss computed with the loss function.\n",
    "\n",
    "coefs_ list, length n_layers - 1\n",
    "The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "\n",
    "intercepts_ list, length n_layers - 1\n",
    "The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "\n",
    "n_iter_ int,\n",
    "The number of iterations the solver has ran.\n",
    "\n",
    "n_layers_ int\n",
    "Number of layers.\n",
    "\n",
    "n_outputs_ int\n",
    "Number of outputs.\n",
    "\n",
    "out_activation_ string\n",
    "Name of the output activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9918133442488744\n",
      "F1-score [0.99478895 0.98091603]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1924\n",
      "           1       0.97      0.99      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.98      0.99      0.99      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9909946786737618\n",
      "F1-score [0.99425587 0.97916667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1924\n",
      "           1       0.96      1.00      0.98       519\n",
      "\n",
      "    accuracy                           0.99      2443\n",
      "   macro avg       0.98      0.99      0.99      2443\n",
      "weighted avg       0.99      0.99      0.99      2443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(128, 64, 32,), alpha=0.1, learning_rate='adaptive', \n",
    "                    activation='tanh', early_stopping=False, momentum=0.9, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\", \"adam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant learning-rate\n",
      "training set score and loss: 0.989, 0.026215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant with momentum\n",
      "training set score and loss: 0.991, 0.025384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling learning-rate\n",
      "training set score and loss: 0.987, 0.084004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-scaling with momentum\n",
      "training set score and loss: 0.986, 0.045019\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n",
      "training set score and loss: 0.991, 0.026063\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, param in zip(labels, params):\n",
    "    print(label)\n",
    "    clf = MLPClassifier(random_state=0, max_iter=200, **param)\n",
    "\n",
    "    # some parameter combinations will not converge as can be seen on the\n",
    "    # plots so they are ignored here\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        clf.fit(X, y)\n",
    "\n",
    "    print(\"training set score and loss: %.3f, %f\" % (clf.score(X, y), clf.loss_))\n",
    "    plt.plot(clf.loss_curve_, label=label)\n",
    "    plt.legend(loc=\"upper center\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0691 - accuracy: 0.9860\n",
      "Epoch 2/50\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0382 - accuracy: 0.9881\n",
      "Epoch 3/50\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0365 - accuracy: 0.98750s - loss:\n",
      "Epoch 4/50\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0337 - accuracy: 0.9874\n",
      "Epoch 5/50\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0311 - accuracy: 0.9891\n",
      "Epoch 6/50\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0295 - accuracy: 0.99000s - loss: 0.0301 - accuracy\n",
      "Epoch 7/50\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0282 - accuracy: 0.9912\n",
      "Epoch 8/50\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0286 - accuracy: 0.9918\n",
      "Epoch 9/50\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0275 - accuracy: 0.9921\n",
      "Epoch 10/50\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0265 - accuracy: 0.9914\n",
      "Epoch 11/50\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0265 - accuracy: 0.9921\n",
      "Epoch 12/50\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0251 - accuracy: 0.99250s - loss: 0.0257 - ac\n",
      "Epoch 13/50\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0259 - accuracy: 0.9918\n",
      "Epoch 14/50\n",
      "5700/5700 [==============================] - 2s 299us/step - loss: 0.0259 - accuracy: 0.9926\n",
      "Epoch 15/50\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0248 - accuracy: 0.99250s\n",
      "Epoch 16/50\n",
      "5700/5700 [==============================] - 2s 273us/step - loss: 0.0240 - accuracy: 0.9925\n",
      "Epoch 17/50\n",
      "5700/5700 [==============================] - 1s 262us/step - loss: 0.0247 - accuracy: 0.9923\n",
      "Epoch 18/50\n",
      "5700/5700 [==============================] - 1s 261us/step - loss: 0.0250 - accuracy: 0.9914\n",
      "Epoch 19/50\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0248 - accuracy: 0.99210s - loss: 0.0237 - accu\n",
      "Epoch 20/50\n",
      "5700/5700 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.99 - 1s 215us/step - loss: 0.0241 - accuracy: 0.9928\n",
      "Epoch 21/50\n",
      "5700/5700 [==============================] - 2s 291us/step - loss: 0.0243 - accuracy: 0.9916\n",
      "Epoch 22/50\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0240 - accuracy: 0.9926\n",
      "Epoch 23/50\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 24/50\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0232 - accuracy: 0.9921\n",
      "Epoch 25/50\n",
      "5700/5700 [==============================] - 2s 348us/step - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "5700/5700 [==============================] - 3s 515us/step - loss: 0.0245 - accuracy: 0.9916\n",
      "Epoch 27/50\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0243 - accuracy: 0.9928\n",
      "Epoch 28/50\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 29/50\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 30/50\n",
      "5700/5700 [==============================] - 1s 186us/step - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 31/50\n",
      "5700/5700 [==============================] - 1s 192us/step - loss: 0.0230 - accuracy: 0.9923\n",
      "Epoch 32/50\n",
      "5700/5700 [==============================] - 2s 271us/step - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 33/50\n",
      "5700/5700 [==============================] - 2s 393us/step - loss: 0.0216 - accuracy: 0.9925\n",
      "Epoch 34/50\n",
      "5700/5700 [==============================] - 2s 268us/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 35/50\n",
      "5700/5700 [==============================] - 2s 295us/step - loss: 0.0216 - accuracy: 0.9921\n",
      "Epoch 36/50\n",
      "5700/5700 [==============================] - 2s 275us/step - loss: 0.0218 - accuracy: 0.99330s - loss: 0.0224 - accuracy: 0. - ETA: 0s - loss: 0.0219 - accura\n",
      "Epoch 37/50\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0212 - accuracy: 0.9928\n",
      "Epoch 38/50\n",
      "5700/5700 [==============================] - 1s 260us/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 39/50\n",
      "5700/5700 [==============================] - 2s 263us/step - loss: 0.0220 - accuracy: 0.9928\n",
      "Epoch 40/50\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 41/50\n",
      "5700/5700 [==============================] - 1s 246us/step - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 42/50\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0218 - accuracy: 0.9919\n",
      "Epoch 43/50\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0214 - accuracy: 0.9925\n",
      "Epoch 44/50\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0211 - accuracy: 0.9925\n",
      "Epoch 45/50\n",
      "5700/5700 [==============================] - 1s 227us/step - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0204 - accuracy: 0.9925\n",
      "Epoch 47/50\n",
      "5700/5700 [==============================] - 2s 272us/step - loss: 0.0211 - accuracy: 0.9930\n",
      "Epoch 48/50\n",
      "5700/5700 [==============================] - 2s 270us/step - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 49/50\n",
      "5700/5700 [==============================] - 2s 281us/step - loss: 0.0202 - accuracy: 0.99320s - loss: 0.0201 - accura\n",
      "Epoch 50/50\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0203 - accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=50, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5700/5700 [==============================] - 1s 89us/step - loss: 0.1731 - accuracy: 0.9681\n",
      "Epoch 2/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0462 - accuracy: 0.9881\n",
      "Epoch 3/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0412 - accuracy: 0.9870\n",
      "Epoch 4/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0393 - accuracy: 0.9865\n",
      "Epoch 5/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0368 - accuracy: 0.9867\n",
      "Epoch 6/50\n",
      "5700/5700 [==============================] - 0s 48us/step - loss: 0.0365 - accuracy: 0.9870\n",
      "Epoch 7/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0355 - accuracy: 0.9870\n",
      "Epoch 8/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0334 - accuracy: 0.9868\n",
      "Epoch 9/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0323 - accuracy: 0.9865\n",
      "Epoch 10/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0316 - accuracy: 0.9868\n",
      "Epoch 11/50\n",
      "5700/5700 [==============================] - 0s 48us/step - loss: 0.0318 - accuracy: 0.9867 0s - loss: 0.0231 - accura\n",
      "Epoch 12/50\n",
      "5700/5700 [==============================] - 0s 51us/step - loss: 0.0307 - accuracy: 0.9872\n",
      "Epoch 13/50\n",
      "5700/5700 [==============================] - 0s 51us/step - loss: 0.0303 - accuracy: 0.9884\n",
      "Epoch 14/50\n",
      "5700/5700 [==============================] - 0s 51us/step - loss: 0.0282 - accuracy: 0.9884\n",
      "Epoch 15/50\n",
      "5700/5700 [==============================] - 0s 51us/step - loss: 0.0282 - accuracy: 0.9891\n",
      "Epoch 16/50\n",
      "5700/5700 [==============================] - 0s 52us/step - loss: 0.0278 - accuracy: 0.9902\n",
      "Epoch 17/50\n",
      "5700/5700 [==============================] - 0s 52us/step - loss: 0.0281 - accuracy: 0.9900\n",
      "Epoch 18/50\n",
      "5700/5700 [==============================] - 0s 45us/step - loss: 0.0267 - accuracy: 0.9902\n",
      "Epoch 19/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0261 - accuracy: 0.9914\n",
      "Epoch 20/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0264 - accuracy: 0.9921\n",
      "Epoch 21/50\n",
      "5700/5700 [==============================] - 0s 46us/step - loss: 0.0251 - accuracy: 0.9933\n",
      "Epoch 22/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 23/50\n",
      "5700/5700 [==============================] - 0s 42us/step - loss: 0.0249 - accuracy: 0.9928\n",
      "Epoch 24/50\n",
      "5700/5700 [==============================] - 0s 48us/step - loss: 0.0248 - accuracy: 0.9918\n",
      "Epoch 25/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 26/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0237 - accuracy: 0.9930\n",
      "Epoch 27/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0245 - accuracy: 0.9932\n",
      "Epoch 28/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0257 - accuracy: 0.9925\n",
      "Epoch 29/50\n",
      "5700/5700 [==============================] - 0s 45us/step - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 30/50\n",
      "5700/5700 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9925\n",
      "Epoch 31/50\n",
      "5700/5700 [==============================] - 0s 47us/step - loss: 0.0235 - accuracy: 0.9930\n",
      "Epoch 32/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0241 - accuracy: 0.9925\n",
      "Epoch 33/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 34/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0231 - accuracy: 0.9940\n",
      "Epoch 35/50\n",
      "5700/5700 [==============================] - 0s 47us/step - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 36/50\n",
      "5700/5700 [==============================] - 0s 49us/step - loss: 0.0242 - accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 39/50\n",
      "5700/5700 [==============================] - 0s 47us/step - loss: 0.0234 - accuracy: 0.9925 0s - loss: 0.0324 - accuracy\n",
      "Epoch 40/50\n",
      "5700/5700 [==============================] - 0s 46us/step - loss: 0.0230 - accuracy: 0.9921\n",
      "Epoch 41/50\n",
      "5700/5700 [==============================] - 0s 42us/step - loss: 0.0237 - accuracy: 0.9926\n",
      "Epoch 42/50\n",
      "5700/5700 [==============================] - 0s 65us/step - loss: 0.0227 - accuracy: 0.9921\n",
      "Epoch 43/50\n",
      "5700/5700 [==============================] - 0s 48us/step - loss: 0.0229 - accuracy: 0.9939\n",
      "Epoch 44/50\n",
      "5700/5700 [==============================] - 0s 46us/step - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 45/50\n",
      "5700/5700 [==============================] - 0s 45us/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 47/50\n",
      "5700/5700 [==============================] - 0s 45us/step - loss: 0.0227 - accuracy: 0.9928\n",
      "Epoch 48/50\n",
      "5700/5700 [==============================] - 0s 44us/step - loss: 0.0232 - accuracy: 0.9933\n",
      "Epoch 49/50\n",
      "5700/5700 [==============================] - 0s 47us/step - loss: 0.0212 - accuracy: 0.9939\n",
      "Epoch 50/50\n",
      "5700/5700 [==============================] - 0s 43us/step - loss: 0.0217 - accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, epochs=50, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1['loss'], label='Loss 10')\n",
    "plt.plot(history2['loss'], label='Loss 50')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443/2443 [==============================] - 0s 44us/step\n",
      "2443/2443 [==============================] - 0s 45us/step\n",
      "Loss 0.027835, Accuracy 0.990585\n",
      "Loss 0.022286, Accuracy 0.992223\n"
     ]
    }
   ],
   "source": [
    "test_loss_1, test_acc_1 = model1.evaluate(X_test, y_test)\n",
    "test_loss_2, test_acc_2 = model2.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.787556283258289\n",
      "F1-score [0.88115411 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      1924\n",
      "           1       0.00      0.00      0.00       519\n",
      "\n",
      "    accuracy                           0.79      2443\n",
      "   macro avg       0.39      0.50      0.44      2443\n",
      "weighted avg       0.62      0.79      0.69      2443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush2017/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5700 samples, validate on 2443 samples\n",
      "Epoch 1/1000\n",
      "5700/5700 [==============================] - 2s 289us/step - loss: 0.0793 - accuracy: 0.9772 - val_loss: 0.0388 - val_accuracy: 0.9869\n",
      "Epoch 2/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0332 - val_accuracy: 0.9906\n",
      "Epoch 3/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0366 - accuracy: 0.9870 - val_loss: 0.0312 - val_accuracy: 0.9902\n",
      "Epoch 4/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0326 - accuracy: 0.9877 - val_loss: 0.0288 - val_accuracy: 0.9902\n",
      "Epoch 5/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.0325 - val_accuracy: 0.9885\n",
      "Epoch 6/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0298 - val_accuracy: 0.9906\n",
      "Epoch 7/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0316 - val_accuracy: 0.9894\n",
      "Epoch 8/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 9/1000\n",
      "5700/5700 [==============================] - 1s 253us/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.0236 - val_accuracy: 0.9922\n",
      "Epoch 10/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.0244 - val_accuracy: 0.9926\n",
      "Epoch 11/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0251 - val_accuracy: 0.9906\n",
      "Epoch 12/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0241 - val_accuracy: 0.9918\n",
      "Epoch 13/1000\n",
      "5700/5700 [==============================] - 1s 254us/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.0234 - val_accuracy: 0.9918\n",
      "Epoch 14/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 15/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.0244 - val_accuracy: 0.9914\n",
      "Epoch 16/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0248 - val_accuracy: 0.9914\n",
      "Epoch 17/1000\n",
      "5700/5700 [==============================] - 1s 247us/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.0218 - val_accuracy: 0.9922\n",
      "Epoch 18/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0258 - val_accuracy: 0.9910\n",
      "Epoch 19/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.0233 - val_accuracy: 0.9922\n",
      "Epoch 20/1000\n",
      "5700/5700 [==============================] - 1s 253us/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 21/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0253 - val_accuracy: 0.9922\n",
      "Epoch 22/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
      "Epoch 23/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
      "Epoch 24/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
      "Epoch 25/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0220 - val_accuracy: 0.9918\n",
      "Epoch 26/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0229 - val_accuracy: 0.9922\n",
      "Epoch 27/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 28/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0241 - val_accuracy: 0.9918\n",
      "Epoch 29/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 30/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0221 - val_accuracy: 0.9918\n",
      "Epoch 31/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 32/1000\n",
      "5700/5700 [==============================] - 1s 260us/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "Epoch 33/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 34/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 35/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0304 - val_accuracy: 0.9881\n",
      "Epoch 36/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0214 - val_accuracy: 0.9922\n",
      "Epoch 37/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 38/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0235 - val_accuracy: 0.9918\n",
      "Epoch 39/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.0215 - val_accuracy: 0.9926\n",
      "Epoch 40/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.0262 - val_accuracy: 0.9922\n",
      "Epoch 41/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0224 - val_accuracy: 0.9926\n",
      "Epoch 42/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0224 - val_accuracy: 0.9918\n",
      "Epoch 43/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.0272 - val_accuracy: 0.9910\n",
      "Epoch 44/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0253 - val_accuracy: 0.9922\n",
      "Epoch 45/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0310 - val_accuracy: 0.9873\n",
      "Epoch 46/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0245 - val_accuracy: 0.9910\n",
      "Epoch 47/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 48/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0314 - val_accuracy: 0.9894\n",
      "Epoch 49/1000\n",
      "5700/5700 [==============================] - 2s 264us/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0224 - val_accuracy: 0.9922\n",
      "Epoch 50/1000\n",
      "5700/5700 [==============================] - 1s 247us/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0226 - val_accuracy: 0.9922\n",
      "Epoch 51/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 52/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 53/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0239 - val_accuracy: 0.9918\n",
      "Epoch 54/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 55/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0229 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "5700/5700 [==============================] - 1s 254us/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0234 - val_accuracy: 0.9930\n",
      "Epoch 57/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0214 - val_accuracy: 0.9922\n",
      "Epoch 58/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0279 - val_accuracy: 0.9922\n",
      "Epoch 59/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0230 - val_accuracy: 0.9922\n",
      "Epoch 60/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0226 - val_accuracy: 0.9910\n",
      "Epoch 61/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.0249 - val_accuracy: 0.9914\n",
      "Epoch 62/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 63/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0248 - val_accuracy: 0.9889\n",
      "Epoch 64/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0227 - val_accuracy: 0.9922\n",
      "Epoch 65/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 66/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0219 - val_accuracy: 0.9922\n",
      "Epoch 67/1000\n",
      "5700/5700 [==============================] - 1s 249us/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0215 - val_accuracy: 0.9918\n",
      "Epoch 68/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0283 - val_accuracy: 0.9898\n",
      "Epoch 69/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9926\n",
      "Epoch 70/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.0250 - val_accuracy: 0.9894\n",
      "Epoch 71/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0194 - accuracy: 0.9930 - val_loss: 0.0224 - val_accuracy: 0.9930\n",
      "Epoch 72/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0235 - val_accuracy: 0.9922\n",
      "Epoch 73/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
      "Epoch 74/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0243 - val_accuracy: 0.9918\n",
      "Epoch 75/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0255 - val_accuracy: 0.9918\n",
      "Epoch 76/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.0236 - val_accuracy: 0.9922\n",
      "Epoch 77/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0196 - accuracy: 0.9923 - val_loss: 0.0210 - val_accuracy: 0.9926\n",
      "Epoch 78/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 79/1000\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 80/1000\n",
      "5700/5700 [==============================] - 1s 250us/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 81/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0232 - val_accuracy: 0.9922\n",
      "Epoch 82/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 83/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0243 - val_accuracy: 0.9918\n",
      "Epoch 84/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.0257 - val_accuracy: 0.9914\n",
      "Epoch 85/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.0276 - val_accuracy: 0.9918\n",
      "Epoch 86/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0243 - val_accuracy: 0.9922\n",
      "Epoch 87/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0395 - val_accuracy: 0.9840\n",
      "Epoch 88/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.0235 - val_accuracy: 0.9926\n",
      "Epoch 89/1000\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 90/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9922\n",
      "Epoch 91/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 92/1000\n",
      "5700/5700 [==============================] - 2s 265us/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.0252 - val_accuracy: 0.9930\n",
      "Epoch 93/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 94/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 95/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0245 - val_accuracy: 0.9918\n",
      "Epoch 96/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0273 - val_accuracy: 0.9922\n",
      "Epoch 97/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0258 - val_accuracy: 0.9910\n",
      "Epoch 98/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 99/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
      "Epoch 100/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9926\n",
      "Epoch 101/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 102/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 103/1000\n",
      "5700/5700 [==============================] - 2s 267us/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0237 - val_accuracy: 0.9918\n",
      "Epoch 104/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0223 - val_accuracy: 0.9922\n",
      "Epoch 105/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0242 - val_accuracy: 0.9918\n",
      "Epoch 106/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 0.0233 - val_accuracy: 0.9922\n",
      "Epoch 107/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0222 - val_accuracy: 0.9918\n",
      "Epoch 108/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.0254 - val_accuracy: 0.9926\n",
      "Epoch 109/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0255 - val_accuracy: 0.9918\n",
      "Epoch 110/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0232 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 0.0234 - val_accuracy: 0.9918\n",
      "Epoch 112/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
      "Epoch 113/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 114/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 115/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
      "Epoch 116/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0169 - accuracy: 0.9935 - val_loss: 0.0273 - val_accuracy: 0.9906\n",
      "Epoch 117/1000\n",
      "5700/5700 [==============================] - 2s 373us/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0215 - val_accuracy: 0.9922\n",
      "Epoch 118/1000\n",
      "5700/5700 [==============================] - 2s 331us/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 119/1000\n",
      "5700/5700 [==============================] - 2s 331us/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0220 - val_accuracy: 0.9922\n",
      "Epoch 120/1000\n",
      "5700/5700 [==============================] - 2s 288us/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.0225 - val_accuracy: 0.9935\n",
      "Epoch 121/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0235 - val_accuracy: 0.9918\n",
      "Epoch 122/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0215 - val_accuracy: 0.9930\n",
      "Epoch 123/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.0258 - val_accuracy: 0.9910\n",
      "Epoch 124/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 125/1000\n",
      "5700/5700 [==============================] - 1s 250us/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 126/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.0229 - val_accuracy: 0.9918\n",
      "Epoch 127/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
      "Epoch 128/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.0264 - val_accuracy: 0.9898\n",
      "Epoch 129/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0249 - val_accuracy: 0.9910\n",
      "Epoch 130/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 131/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0271 - val_accuracy: 0.9922\n",
      "Epoch 132/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0254 - val_accuracy: 0.9910\n",
      "Epoch 133/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0289 - val_accuracy: 0.9902\n",
      "Epoch 134/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.0234 - val_accuracy: 0.9922\n",
      "Epoch 135/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 136/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 0.0254 - val_accuracy: 0.9935\n",
      "Epoch 137/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0275 - val_accuracy: 0.9926\n",
      "Epoch 138/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 139/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0251 - val_accuracy: 0.9935\n",
      "Epoch 140/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.0259 - val_accuracy: 0.9922\n",
      "Epoch 141/1000\n",
      "5700/5700 [==============================] - 1s 249us/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0262 - val_accuracy: 0.9930\n",
      "Epoch 142/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.0263 - val_accuracy: 0.9914\n",
      "Epoch 143/1000\n",
      "5700/5700 [==============================] - 2s 320us/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
      "Epoch 144/1000\n",
      "5700/5700 [==============================] - 2s 291us/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.0276 - val_accuracy: 0.9922\n",
      "Epoch 145/1000\n",
      "5700/5700 [==============================] - 2s 279us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0293 - val_accuracy: 0.9918\n",
      "Epoch 146/1000\n",
      "5700/5700 [==============================] - 2s 281us/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0271 - val_accuracy: 0.9922\n",
      "Epoch 147/1000\n",
      "5700/5700 [==============================] - 2s 295us/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0253 - val_accuracy: 0.9926\n",
      "Epoch 148/1000\n",
      "5700/5700 [==============================] - 2s 408us/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0256 - val_accuracy: 0.9935\n",
      "Epoch 149/1000\n",
      "5700/5700 [==============================] - 2s 402us/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0290 - val_accuracy: 0.9898\n",
      "Epoch 150/1000\n",
      "5700/5700 [==============================] - 2s 338us/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.0251 - val_accuracy: 0.9926\n",
      "Epoch 151/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
      "Epoch 152/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.0267 - val_accuracy: 0.9935\n",
      "Epoch 153/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0258 - val_accuracy: 0.9918\n",
      "Epoch 154/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.0277 - val_accuracy: 0.9889\n",
      "Epoch 155/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.0240 - val_accuracy: 0.9939\n",
      "Epoch 156/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0263 - val_accuracy: 0.9918\n",
      "Epoch 157/1000\n",
      "5700/5700 [==============================] - 1s 262us/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9914\n",
      "Epoch 158/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.0255 - val_accuracy: 0.9914\n",
      "Epoch 159/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.0274 - val_accuracy: 0.9898\n",
      "Epoch 160/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.0274 - val_accuracy: 0.9910\n",
      "Epoch 161/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.0260 - val_accuracy: 0.9914\n",
      "Epoch 162/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9918\n",
      "Epoch 163/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.0289 - val_accuracy: 0.9894\n",
      "Epoch 164/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0267 - val_accuracy: 0.9910\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 166/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0268 - val_accuracy: 0.9922\n",
      "Epoch 167/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0281 - val_accuracy: 0.9914\n",
      "Epoch 168/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0294 - val_accuracy: 0.9914\n",
      "Epoch 169/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0284 - val_accuracy: 0.9889\n",
      "Epoch 170/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9906\n",
      "Epoch 171/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0266 - val_accuracy: 0.9914\n",
      "Epoch 172/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0288 - val_accuracy: 0.9914\n",
      "Epoch 173/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 174/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9889\n",
      "Epoch 175/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0282 - val_accuracy: 0.9935\n",
      "Epoch 176/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0270 - val_accuracy: 0.9922\n",
      "Epoch 177/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9906\n",
      "Epoch 178/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0268 - val_accuracy: 0.9918\n",
      "Epoch 179/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0301 - val_accuracy: 0.9918\n",
      "Epoch 180/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0251 - val_accuracy: 0.9914\n",
      "Epoch 181/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0253 - val_accuracy: 0.9918\n",
      "Epoch 182/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0296 - val_accuracy: 0.9914\n",
      "Epoch 183/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0267 - val_accuracy: 0.9910\n",
      "Epoch 184/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0152 - accuracy: 0.9940 - val_loss: 0.0300 - val_accuracy: 0.9910\n",
      "Epoch 185/1000\n",
      "5700/5700 [==============================] - 1s 197us/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.0265 - val_accuracy: 0.9918\n",
      "Epoch 186/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0282 - val_accuracy: 0.9918\n",
      "Epoch 187/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
      "Epoch 188/1000\n",
      "5700/5700 [==============================] - 2s 270us/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.0276 - val_accuracy: 0.9902\n",
      "Epoch 189/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 190/1000\n",
      "5700/5700 [==============================] - 2s 286us/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.0285 - val_accuracy: 0.9902\n",
      "Epoch 191/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
      "Epoch 192/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
      "Epoch 193/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.0261 - val_accuracy: 0.9930\n",
      "Epoch 194/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.0280 - val_accuracy: 0.9898\n",
      "Epoch 195/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0282 - val_accuracy: 0.9914\n",
      "Epoch 196/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
      "Epoch 197/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 0.0256 - val_accuracy: 0.9922\n",
      "Epoch 198/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0278 - val_accuracy: 0.9910\n",
      "Epoch 199/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9918\n",
      "Epoch 200/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.0299 - val_accuracy: 0.9894\n",
      "Epoch 201/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0277 - val_accuracy: 0.9910\n",
      "Epoch 202/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0302 - val_accuracy: 0.9898\n",
      "Epoch 203/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.0249 - val_accuracy: 0.9918\n",
      "Epoch 204/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0248 - val_accuracy: 0.9922\n",
      "Epoch 205/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9906\n",
      "Epoch 206/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 0.0269 - val_accuracy: 0.9918\n",
      "Epoch 207/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.0273 - val_accuracy: 0.9922\n",
      "Epoch 208/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0286 - val_accuracy: 0.9910\n",
      "Epoch 209/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0270 - val_accuracy: 0.9914\n",
      "Epoch 210/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
      "Epoch 211/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0261 - val_accuracy: 0.9918\n",
      "Epoch 212/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0304 - val_accuracy: 0.9914\n",
      "Epoch 213/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.0314 - val_accuracy: 0.9906\n",
      "Epoch 214/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
      "Epoch 215/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.0276 - val_accuracy: 0.9910\n",
      "Epoch 216/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0289 - val_accuracy: 0.9922\n",
      "Epoch 217/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0289 - val_accuracy: 0.9914\n",
      "Epoch 218/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 219/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0267 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9922\n",
      "Epoch 221/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 222/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0297 - val_accuracy: 0.9922\n",
      "Epoch 223/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0313 - val_accuracy: 0.9918\n",
      "Epoch 224/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0280 - val_accuracy: 0.9926\n",
      "Epoch 225/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.0317 - val_accuracy: 0.9906\n",
      "Epoch 226/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0309 - val_accuracy: 0.9922\n",
      "Epoch 227/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0271 - val_accuracy: 0.9935\n",
      "Epoch 228/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.0323 - val_accuracy: 0.9918\n",
      "Epoch 229/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0312 - val_accuracy: 0.9914\n",
      "Epoch 230/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 231/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0275 - val_accuracy: 0.9906\n",
      "Epoch 232/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.0297 - val_accuracy: 0.9910\n",
      "Epoch 233/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0306 - val_accuracy: 0.9910\n",
      "Epoch 234/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0309 - val_accuracy: 0.9922\n",
      "Epoch 235/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 236/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.0266 - val_accuracy: 0.9926\n",
      "Epoch 237/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0332 - val_accuracy: 0.9910\n",
      "Epoch 238/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
      "Epoch 239/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0335 - val_accuracy: 0.9889\n",
      "Epoch 240/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0316 - val_accuracy: 0.9926\n",
      "Epoch 241/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.0267 - val_accuracy: 0.9918\n",
      "Epoch 242/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.0291 - val_accuracy: 0.9902\n",
      "Epoch 243/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0293 - val_accuracy: 0.9918\n",
      "Epoch 244/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
      "Epoch 245/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0335 - val_accuracy: 0.9877\n",
      "Epoch 246/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0285 - val_accuracy: 0.9914\n",
      "Epoch 247/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.0296 - val_accuracy: 0.9914\n",
      "Epoch 248/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0296 - val_accuracy: 0.9922\n",
      "Epoch 249/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.0309 - val_accuracy: 0.9914\n",
      "Epoch 250/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0310 - val_accuracy: 0.9906\n",
      "Epoch 251/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0298 - val_accuracy: 0.9918\n",
      "Epoch 252/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0287 - val_accuracy: 0.9926\n",
      "Epoch 253/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
      "Epoch 254/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.0298 - val_accuracy: 0.9930\n",
      "Epoch 255/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0312 - val_accuracy: 0.9926\n",
      "Epoch 256/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.0324 - val_accuracy: 0.9910\n",
      "Epoch 257/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 258/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0322 - val_accuracy: 0.9918\n",
      "Epoch 259/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0292 - val_accuracy: 0.9935\n",
      "Epoch 260/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
      "Epoch 261/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 262/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0304 - val_accuracy: 0.9922\n",
      "Epoch 263/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 264/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.0278 - val_accuracy: 0.9910\n",
      "Epoch 265/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
      "Epoch 266/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0281 - val_accuracy: 0.9914\n",
      "Epoch 267/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0307 - val_accuracy: 0.9910\n",
      "Epoch 268/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0296 - val_accuracy: 0.9918\n",
      "Epoch 269/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0308 - val_accuracy: 0.9910\n",
      "Epoch 270/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0304 - val_accuracy: 0.9910\n",
      "Epoch 271/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0287 - val_accuracy: 0.9910\n",
      "Epoch 272/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.0301 - val_accuracy: 0.9910\n",
      "Epoch 273/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0336 - val_accuracy: 0.9906\n",
      "Epoch 274/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0136 - accuracy: 0.9946 - val_loss: 0.0315 - val_accuracy: 0.9926\n",
      "Epoch 275/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0318 - val_accuracy: 0.9889\n",
      "Epoch 276/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0310 - val_accuracy: 0.9922\n",
      "Epoch 277/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0343 - val_accuracy: 0.9910\n",
      "Epoch 278/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
      "Epoch 279/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.0327 - val_accuracy: 0.9906\n",
      "Epoch 280/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0317 - val_accuracy: 0.9922\n",
      "Epoch 281/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 282/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0380 - val_accuracy: 0.9873\n",
      "Epoch 283/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 284/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0318 - val_accuracy: 0.9914\n",
      "Epoch 285/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0341 - val_accuracy: 0.9906\n",
      "Epoch 286/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0303 - val_accuracy: 0.9922\n",
      "Epoch 287/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 288/1000\n",
      "5700/5700 [==============================] - 1s 198us/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 289/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0297 - val_accuracy: 0.9918\n",
      "Epoch 290/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0322 - val_accuracy: 0.9922\n",
      "Epoch 291/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.0305 - val_accuracy: 0.9914\n",
      "Epoch 292/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0301 - val_accuracy: 0.9906\n",
      "Epoch 293/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0135 - accuracy: 0.9944 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
      "Epoch 294/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
      "Epoch 295/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 296/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0313 - val_accuracy: 0.9922\n",
      "Epoch 297/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0339 - val_accuracy: 0.9902\n",
      "Epoch 298/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0323 - val_accuracy: 0.9910\n",
      "Epoch 299/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0142 - accuracy: 0.9944 - val_loss: 0.0333 - val_accuracy: 0.9914\n",
      "Epoch 300/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0346 - val_accuracy: 0.9889\n",
      "Epoch 301/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 302/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 303/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.0329 - val_accuracy: 0.9914\n",
      "Epoch 304/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0279 - val_accuracy: 0.9910\n",
      "Epoch 305/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
      "Epoch 306/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9926\n",
      "Epoch 307/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0298 - val_accuracy: 0.9910\n",
      "Epoch 308/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9902\n",
      "Epoch 309/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 310/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0300 - val_accuracy: 0.9930\n",
      "Epoch 311/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0283 - val_accuracy: 0.9930\n",
      "Epoch 312/1000\n",
      "5700/5700 [==============================] - 2s 289us/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.0311 - val_accuracy: 0.9914\n",
      "Epoch 313/1000\n",
      "5700/5700 [==============================] - 3s 470us/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.0301 - val_accuracy: 0.9918\n",
      "Epoch 314/1000\n",
      "5700/5700 [==============================] - 3s 481us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0296 - val_accuracy: 0.9894\n",
      "Epoch 315/1000\n",
      "5700/5700 [==============================] - 3s 477us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 316/1000\n",
      "5700/5700 [==============================] - 2s 385us/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.0282 - val_accuracy: 0.9918\n",
      "Epoch 317/1000\n",
      "5700/5700 [==============================] - 2s 340us/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0292 - val_accuracy: 0.9918\n",
      "Epoch 318/1000\n",
      "5700/5700 [==============================] - 2s 350us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0261 - val_accuracy: 0.9914\n",
      "Epoch 319/1000\n",
      "5700/5700 [==============================] - 2s 341us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0291 - val_accuracy: 0.9922\n",
      "Epoch 320/1000\n",
      "5700/5700 [==============================] - 2s 402us/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
      "Epoch 321/1000\n",
      "5700/5700 [==============================] - 2s 356us/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.0308 - val_accuracy: 0.9914\n",
      "Epoch 322/1000\n",
      "5700/5700 [==============================] - 3s 482us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0322 - val_accuracy: 0.9910\n",
      "Epoch 323/1000\n",
      "5700/5700 [==============================] - 3s 543us/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0313 - val_accuracy: 0.9918\n",
      "Epoch 324/1000\n",
      "5700/5700 [==============================] - 2s 421us/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 325/1000\n",
      "5700/5700 [==============================] - 2s 419us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0304 - val_accuracy: 0.9926\n",
      "Epoch 326/1000\n",
      "5700/5700 [==============================] - 3s 460us/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.0290 - val_accuracy: 0.9939\n",
      "Epoch 327/1000\n",
      "5700/5700 [==============================] - 3s 444us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "Epoch 328/1000\n",
      "5700/5700 [==============================] - 2s 404us/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "5700/5700 [==============================] - 2s 405us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0318 - val_accuracy: 0.9914\n",
      "Epoch 330/1000\n",
      "5700/5700 [==============================] - 2s 421us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0344 - val_accuracy: 0.9910\n",
      "Epoch 331/1000\n",
      "5700/5700 [==============================] - 2s 417us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 332/1000\n",
      "5700/5700 [==============================] - 2s 427us/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 333/1000\n",
      "5700/5700 [==============================] - 2s 415us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9906\n",
      "Epoch 334/1000\n",
      "5700/5700 [==============================] - 2s 419us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0356 - val_accuracy: 0.9902\n",
      "Epoch 335/1000\n",
      "5700/5700 [==============================] - 3s 480us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0331 - val_accuracy: 0.9926\n",
      "Epoch 336/1000\n",
      "5700/5700 [==============================] - 2s 384us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9914\n",
      "Epoch 337/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0323 - val_accuracy: 0.9922\n",
      "Epoch 338/1000\n",
      "5700/5700 [==============================] - 2s 282us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0330 - val_accuracy: 0.9902\n",
      "Epoch 339/1000\n",
      "5700/5700 [==============================] - 2s 331us/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0330 - val_accuracy: 0.9918\n",
      "Epoch 340/1000\n",
      "5700/5700 [==============================] - 2s 300us/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 341/1000\n",
      "5700/5700 [==============================] - 2s 280us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0300 - val_accuracy: 0.9930\n",
      "Epoch 342/1000\n",
      "5700/5700 [==============================] - 2s 284us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0348 - val_accuracy: 0.9906\n",
      "Epoch 343/1000\n",
      "5700/5700 [==============================] - 2s 303us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0313 - val_accuracy: 0.9914\n",
      "Epoch 344/1000\n",
      "5700/5700 [==============================] - 2s 312us/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.0321 - val_accuracy: 0.9918\n",
      "Epoch 345/1000\n",
      "5700/5700 [==============================] - 2s 280us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0303 - val_accuracy: 0.9914\n",
      "Epoch 346/1000\n",
      "5700/5700 [==============================] - 2s 279us/step - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.0332 - val_accuracy: 0.9902\n",
      "Epoch 347/1000\n",
      "5700/5700 [==============================] - 2s 294us/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0344 - val_accuracy: 0.9914\n",
      "Epoch 348/1000\n",
      "5700/5700 [==============================] - 2s 329us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0328 - val_accuracy: 0.9918\n",
      "Epoch 349/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0341 - val_accuracy: 0.9910\n",
      "Epoch 350/1000\n",
      "5700/5700 [==============================] - 1s 261us/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0335 - val_accuracy: 0.9914\n",
      "Epoch 351/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0330 - val_accuracy: 0.9914\n",
      "Epoch 352/1000\n",
      "5700/5700 [==============================] - 2s 278us/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0346 - val_accuracy: 0.9910\n",
      "Epoch 353/1000\n",
      "5700/5700 [==============================] - 2s 320us/step - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.0331 - val_accuracy: 0.9914\n",
      "Epoch 354/1000\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0348 - val_accuracy: 0.9922\n",
      "Epoch 355/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0337 - val_accuracy: 0.9914\n",
      "Epoch 356/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 357/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0318 - val_accuracy: 0.9914\n",
      "Epoch 358/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
      "Epoch 359/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0318 - val_accuracy: 0.9926\n",
      "Epoch 360/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0331 - val_accuracy: 0.9918\n",
      "Epoch 361/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0309 - val_accuracy: 0.9926\n",
      "Epoch 362/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0307 - val_accuracy: 0.9922\n",
      "Epoch 363/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.0304 - val_accuracy: 0.9922\n",
      "Epoch 364/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9926\n",
      "Epoch 365/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0312 - val_accuracy: 0.9918\n",
      "Epoch 366/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0336 - val_accuracy: 0.9926\n",
      "Epoch 367/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 368/1000\n",
      "5700/5700 [==============================] - 1s 219us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0344 - val_accuracy: 0.9902\n",
      "Epoch 369/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0317 - val_accuracy: 0.9914\n",
      "Epoch 370/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0332 - val_accuracy: 0.9922\n",
      "Epoch 371/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9914\n",
      "Epoch 372/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
      "Epoch 373/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0323 - val_accuracy: 0.9910\n",
      "Epoch 374/1000\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0341 - val_accuracy: 0.9926\n",
      "Epoch 375/1000\n",
      "5700/5700 [==============================] - 1s 262us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0319 - val_accuracy: 0.9922\n",
      "Epoch 376/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0331 - val_accuracy: 0.9914\n",
      "Epoch 377/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 378/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0307 - val_accuracy: 0.9918\n",
      "Epoch 379/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 380/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
      "Epoch 381/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0334 - val_accuracy: 0.9922\n",
      "Epoch 382/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9906\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0320 - val_accuracy: 0.9943\n",
      "Epoch 384/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0345 - val_accuracy: 0.9918\n",
      "Epoch 385/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0367 - val_accuracy: 0.9914\n",
      "Epoch 386/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0350 - val_accuracy: 0.9906\n",
      "Epoch 387/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0332 - val_accuracy: 0.9902\n",
      "Epoch 388/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0347 - val_accuracy: 0.9914\n",
      "Epoch 389/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
      "Epoch 390/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0397 - val_accuracy: 0.9902\n",
      "Epoch 391/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0405 - val_accuracy: 0.9922\n",
      "Epoch 392/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0348 - val_accuracy: 0.9910\n",
      "Epoch 393/1000\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0340 - val_accuracy: 0.9914\n",
      "Epoch 394/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
      "Epoch 395/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
      "Epoch 396/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.0318 - val_accuracy: 0.9918\n",
      "Epoch 397/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0383 - val_accuracy: 0.9906\n",
      "Epoch 398/1000\n",
      "5700/5700 [==============================] - 1s 227us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0367 - val_accuracy: 0.9906\n",
      "Epoch 399/1000\n",
      "5700/5700 [==============================] - 1s 219us/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0337 - val_accuracy: 0.9922\n",
      "Epoch 400/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0339 - val_accuracy: 0.9906\n",
      "Epoch 401/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 402/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0332 - val_accuracy: 0.9935\n",
      "Epoch 403/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0509 - val_accuracy: 0.9914\n",
      "Epoch 404/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0354 - val_accuracy: 0.9914\n",
      "Epoch 405/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 406/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0349 - val_accuracy: 0.9910\n",
      "Epoch 407/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.0320 - val_accuracy: 0.9910\n",
      "Epoch 408/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0299 - val_accuracy: 0.9922\n",
      "Epoch 409/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0318 - val_accuracy: 0.9922\n",
      "Epoch 410/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 411/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0315 - val_accuracy: 0.9914\n",
      "Epoch 412/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 413/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9918\n",
      "Epoch 414/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0322 - val_accuracy: 0.9926\n",
      "Epoch 415/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 416/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0152 - accuracy: 0.9939 - val_loss: 0.0312 - val_accuracy: 0.9926\n",
      "Epoch 417/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.0322 - val_accuracy: 0.9922\n",
      "Epoch 418/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0360 - val_accuracy: 0.9914\n",
      "Epoch 419/1000\n",
      "5700/5700 [==============================] - 2s 290us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.0332 - val_accuracy: 0.9902\n",
      "Epoch 420/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0329 - val_accuracy: 0.9898\n",
      "Epoch 421/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9918\n",
      "Epoch 422/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0354 - val_accuracy: 0.9930\n",
      "Epoch 423/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0388 - val_accuracy: 0.9914\n",
      "Epoch 424/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9918\n",
      "Epoch 425/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0349 - val_accuracy: 0.9894\n",
      "Epoch 426/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 0.0397 - val_accuracy: 0.9898\n",
      "Epoch 427/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9918\n",
      "Epoch 428/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.0334 - val_accuracy: 0.9918\n",
      "Epoch 429/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0321 - val_accuracy: 0.9918\n",
      "Epoch 430/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0442 - val_accuracy: 0.9926\n",
      "Epoch 431/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0337 - val_accuracy: 0.9914\n",
      "Epoch 432/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 433/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9943\n",
      "Epoch 434/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0320 - val_accuracy: 0.9914\n",
      "Epoch 435/1000\n",
      "5700/5700 [==============================] - 1s 213us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0299 - val_accuracy: 0.9930\n",
      "Epoch 436/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0275 - val_accuracy: 0.9926\n",
      "Epoch 437/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0328 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0294 - val_accuracy: 0.9926\n",
      "Epoch 439/1000\n",
      "5700/5700 [==============================] - 1s 254us/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0330 - val_accuracy: 0.9906\n",
      "Epoch 440/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0120 - accuracy: 0.9949 - val_loss: 0.0322 - val_accuracy: 0.9922\n",
      "Epoch 441/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0330 - val_accuracy: 0.9906\n",
      "Epoch 442/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0352 - val_accuracy: 0.9906\n",
      "Epoch 443/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0305 - val_accuracy: 0.9930\n",
      "Epoch 444/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0353 - val_accuracy: 0.9910\n",
      "Epoch 445/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0364 - val_accuracy: 0.9930\n",
      "Epoch 446/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0353 - val_accuracy: 0.9918\n",
      "Epoch 447/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0326 - val_accuracy: 0.9906\n",
      "Epoch 448/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0306 - val_accuracy: 0.9914\n",
      "Epoch 449/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
      "Epoch 450/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
      "Epoch 451/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 452/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0125 - accuracy: 0.9947 - val_loss: 0.0349 - val_accuracy: 0.9930\n",
      "Epoch 453/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0358 - val_accuracy: 0.9894\n",
      "Epoch 454/1000\n",
      "5700/5700 [==============================] - 2s 360us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9914\n",
      "Epoch 455/1000\n",
      "5700/5700 [==============================] - 1s 250us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0344 - val_accuracy: 0.9914\n",
      "Epoch 456/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9910\n",
      "Epoch 457/1000\n",
      "5700/5700 [==============================] - 1s 263us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 458/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0364 - val_accuracy: 0.9910\n",
      "Epoch 459/1000\n",
      "5700/5700 [==============================] - 2s 271us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 460/1000\n",
      "5700/5700 [==============================] - 2s 293us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0316 - val_accuracy: 0.9918\n",
      "Epoch 461/1000\n",
      "5700/5700 [==============================] - 2s 287us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0319 - val_accuracy: 0.9935\n",
      "Epoch 462/1000\n",
      "5700/5700 [==============================] - 2s 292us/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
      "Epoch 463/1000\n",
      "5700/5700 [==============================] - 2s 275us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 464/1000\n",
      "5700/5700 [==============================] - 1s 263us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0308 - val_accuracy: 0.9930\n",
      "Epoch 465/1000\n",
      "5700/5700 [==============================] - 1s 259us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 466/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
      "Epoch 467/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0348 - val_accuracy: 0.9906\n",
      "Epoch 468/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0339 - val_accuracy: 0.9914\n",
      "Epoch 469/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0364 - val_accuracy: 0.9918\n",
      "Epoch 470/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0319 - val_accuracy: 0.9926\n",
      "Epoch 471/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9930\n",
      "Epoch 472/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0340 - val_accuracy: 0.9906\n",
      "Epoch 473/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 474/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
      "Epoch 475/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0335 - val_accuracy: 0.9910\n",
      "Epoch 476/1000\n",
      "5700/5700 [==============================] - 2s 267us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 477/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 478/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0316 - val_accuracy: 0.9914\n",
      "Epoch 479/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0332 - val_accuracy: 0.9918\n",
      "Epoch 480/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 481/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0344 - val_accuracy: 0.9918\n",
      "Epoch 482/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9918\n",
      "Epoch 483/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 484/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 485/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0346 - val_accuracy: 0.9914\n",
      "Epoch 486/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9935\n",
      "Epoch 487/1000\n",
      "5700/5700 [==============================] - 1s 260us/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.0395 - val_accuracy: 0.9898\n",
      "Epoch 488/1000\n",
      "5700/5700 [==============================] - 1s 261us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0311 - val_accuracy: 0.9930\n",
      "Epoch 489/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 490/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0311 - val_accuracy: 0.9935\n",
      "Epoch 491/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0331 - val_accuracy: 0.9918\n",
      "Epoch 493/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0336 - val_accuracy: 0.9926\n",
      "Epoch 494/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.0322 - val_accuracy: 0.9922\n",
      "Epoch 495/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0331 - val_accuracy: 0.9930\n",
      "Epoch 496/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0131 - accuracy: 0.9949 - val_loss: 0.0343 - val_accuracy: 0.9914\n",
      "Epoch 497/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0334 - val_accuracy: 0.9910\n",
      "Epoch 498/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0315 - val_accuracy: 0.9926\n",
      "Epoch 499/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0326 - val_accuracy: 0.9922\n",
      "Epoch 500/1000\n",
      "5700/5700 [==============================] - 1s 254us/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0318 - val_accuracy: 0.9926\n",
      "Epoch 501/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0300 - val_accuracy: 0.9918\n",
      "Epoch 502/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.0304 - val_accuracy: 0.9935\n",
      "Epoch 503/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0313 - val_accuracy: 0.9922\n",
      "Epoch 504/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.0352 - val_accuracy: 0.9914\n",
      "Epoch 505/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0314 - val_accuracy: 0.9930\n",
      "Epoch 506/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 507/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 508/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0332 - val_accuracy: 0.9926\n",
      "Epoch 509/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0309 - val_accuracy: 0.9930\n",
      "Epoch 510/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0311 - val_accuracy: 0.9926\n",
      "Epoch 511/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
      "Epoch 512/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0127 - accuracy: 0.9953 - val_loss: 0.0328 - val_accuracy: 0.9914\n",
      "Epoch 513/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0331 - val_accuracy: 0.9906\n",
      "Epoch 514/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0340 - val_accuracy: 0.9902\n",
      "Epoch 515/1000\n",
      "5700/5700 [==============================] - 2s 264us/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9922\n",
      "Epoch 516/1000\n",
      "5700/5700 [==============================] - 2s 281us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0320 - val_accuracy: 0.9935\n",
      "Epoch 517/1000\n",
      "5700/5700 [==============================] - 2s 289us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 518/1000\n",
      "5700/5700 [==============================] - 2s 311us/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0375 - val_accuracy: 0.9914\n",
      "Epoch 519/1000\n",
      "5700/5700 [==============================] - 2s 263us/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0369 - val_accuracy: 0.9935\n",
      "Epoch 520/1000\n",
      "5700/5700 [==============================] - 2s 272us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0362 - val_accuracy: 0.9926\n",
      "Epoch 521/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9910\n",
      "Epoch 522/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0323 - val_accuracy: 0.9922\n",
      "Epoch 523/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
      "Epoch 524/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0335 - val_accuracy: 0.9918\n",
      "Epoch 525/1000\n",
      "5700/5700 [==============================] - 2s 361us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 526/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.0318 - val_accuracy: 0.9922\n",
      "Epoch 527/1000\n",
      "5700/5700 [==============================] - 2s 266us/step - loss: 0.0122 - accuracy: 0.9946 - val_loss: 0.0327 - val_accuracy: 0.9914\n",
      "Epoch 528/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 529/1000\n",
      "5700/5700 [==============================] - 1s 250us/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 530/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 531/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 532/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.0339 - val_accuracy: 0.9918\n",
      "Epoch 533/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0112 - accuracy: 0.9956 - val_loss: 0.0347 - val_accuracy: 0.9922\n",
      "Epoch 534/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0346 - val_accuracy: 0.9902\n",
      "Epoch 535/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0343 - val_accuracy: 0.9930\n",
      "Epoch 536/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0319 - val_accuracy: 0.9930\n",
      "Epoch 537/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
      "Epoch 538/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.0297 - val_accuracy: 0.9914\n",
      "Epoch 539/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0300 - val_accuracy: 0.9926\n",
      "Epoch 540/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0313 - val_accuracy: 0.9914\n",
      "Epoch 541/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0332 - val_accuracy: 0.9930\n",
      "Epoch 542/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0290 - val_accuracy: 0.9935\n",
      "Epoch 543/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.0305 - val_accuracy: 0.9918\n",
      "Epoch 544/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
      "Epoch 545/1000\n",
      "5700/5700 [==============================] - 1s 245us/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0304 - val_accuracy: 0.9914\n",
      "Epoch 546/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0323 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0285 - val_accuracy: 0.9935\n",
      "Epoch 548/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0337 - val_accuracy: 0.9910\n",
      "Epoch 549/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0326 - val_accuracy: 0.9910\n",
      "Epoch 550/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0329 - val_accuracy: 0.9930\n",
      "Epoch 551/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0340 - val_accuracy: 0.9926\n",
      "Epoch 552/1000\n",
      "5700/5700 [==============================] - 2s 329us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0312 - val_accuracy: 0.9922\n",
      "Epoch 553/1000\n",
      "5700/5700 [==============================] - 2s 290us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "Epoch 554/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0293 - val_accuracy: 0.9947\n",
      "Epoch 555/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0281 - val_accuracy: 0.9930\n",
      "Epoch 556/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0316 - val_accuracy: 0.9918\n",
      "Epoch 557/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.0308 - val_accuracy: 0.9918\n",
      "Epoch 558/1000\n",
      "5700/5700 [==============================] - 1s 246us/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0313 - val_accuracy: 0.9918\n",
      "Epoch 559/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0330 - val_accuracy: 0.9922\n",
      "Epoch 560/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0345 - val_accuracy: 0.9898\n",
      "Epoch 561/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 562/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0305 - val_accuracy: 0.9930\n",
      "Epoch 563/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0329 - val_accuracy: 0.9930\n",
      "Epoch 564/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0364 - val_accuracy: 0.9914\n",
      "Epoch 565/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
      "Epoch 566/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 567/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0330 - val_accuracy: 0.9910\n",
      "Epoch 568/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0302 - val_accuracy: 0.9935\n",
      "Epoch 569/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0315 - val_accuracy: 0.9922\n",
      "Epoch 570/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0301 - val_accuracy: 0.9926\n",
      "Epoch 571/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0318 - val_accuracy: 0.9930\n",
      "Epoch 572/1000\n",
      "5700/5700 [==============================] - 2s 321us/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.0329 - val_accuracy: 0.9939\n",
      "Epoch 573/1000\n",
      "5700/5700 [==============================] - 2s 301us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0365 - val_accuracy: 0.9906\n",
      "Epoch 574/1000\n",
      "5700/5700 [==============================] - 2s 295us/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 575/1000\n",
      "5700/5700 [==============================] - 2s 334us/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 576/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0320 - val_accuracy: 0.9935\n",
      "Epoch 577/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0331 - val_accuracy: 0.9906\n",
      "Epoch 578/1000\n",
      "5700/5700 [==============================] - 1s 246us/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.0332 - val_accuracy: 0.9922\n",
      "Epoch 579/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 580/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0322 - val_accuracy: 0.9935\n",
      "Epoch 581/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0339 - val_accuracy: 0.9926\n",
      "Epoch 582/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0362 - val_accuracy: 0.9930\n",
      "Epoch 583/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0320 - val_accuracy: 0.9914\n",
      "Epoch 584/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 585/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0103 - accuracy: 0.9954 - val_loss: 0.0337 - val_accuracy: 0.9926\n",
      "Epoch 586/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 587/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 0.0298 - val_accuracy: 0.9939\n",
      "Epoch 588/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0332 - val_accuracy: 0.9939\n",
      "Epoch 589/1000\n",
      "5700/5700 [==============================] - 1s 248us/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0312 - val_accuracy: 0.9930\n",
      "Epoch 590/1000\n",
      "5700/5700 [==============================] - 1s 251us/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.0311 - val_accuracy: 0.9935\n",
      "Epoch 591/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0309 - val_accuracy: 0.9939\n",
      "Epoch 592/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "Epoch 593/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0307 - val_accuracy: 0.9930\n",
      "Epoch 594/1000\n",
      "5700/5700 [==============================] - 1s 261us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0313 - val_accuracy: 0.9922\n",
      "Epoch 595/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 0.0318 - val_accuracy: 0.9930\n",
      "Epoch 596/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0346 - val_accuracy: 0.9926\n",
      "Epoch 597/1000\n",
      "5700/5700 [==============================] - 1s 246us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0379 - val_accuracy: 0.9918\n",
      "Epoch 598/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0386 - val_accuracy: 0.9935\n",
      "Epoch 599/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "Epoch 600/1000\n",
      "5700/5700 [==============================] - 1s 240us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0350 - val_accuracy: 0.9918\n",
      "Epoch 602/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 603/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0353 - val_accuracy: 0.9898\n",
      "Epoch 604/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.0323 - val_accuracy: 0.9918\n",
      "Epoch 605/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0356 - val_accuracy: 0.9930\n",
      "Epoch 606/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0293 - val_accuracy: 0.9943\n",
      "Epoch 607/1000\n",
      "5700/5700 [==============================] - 1s 243us/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0317 - val_accuracy: 0.9943\n",
      "Epoch 608/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0310 - val_accuracy: 0.9935\n",
      "Epoch 609/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0115 - accuracy: 0.9951 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 610/1000\n",
      "5700/5700 [==============================] - 1s 241us/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0355 - val_accuracy: 0.9914\n",
      "Epoch 611/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9935\n",
      "Epoch 612/1000\n",
      "5700/5700 [==============================] - 1s 250us/step - loss: 0.0112 - accuracy: 0.9951 - val_loss: 0.0308 - val_accuracy: 0.9926\n",
      "Epoch 613/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9935\n",
      "Epoch 614/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0319 - val_accuracy: 0.9918\n",
      "Epoch 615/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0306 - val_accuracy: 0.9935\n",
      "Epoch 616/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0324 - val_accuracy: 0.9926\n",
      "Epoch 617/1000\n",
      "5700/5700 [==============================] - 2s 273us/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.0284 - val_accuracy: 0.9947\n",
      "Epoch 618/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0314 - val_accuracy: 0.9918\n",
      "Epoch 619/1000\n",
      "5700/5700 [==============================] - 1s 259us/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 620/1000\n",
      "5700/5700 [==============================] - 2s 421us/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9930\n",
      "Epoch 621/1000\n",
      "5700/5700 [==============================] - 2s 436us/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.0308 - val_accuracy: 0.9930\n",
      "Epoch 622/1000\n",
      "5700/5700 [==============================] - 2s 369us/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0367 - val_accuracy: 0.9930\n",
      "Epoch 623/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0301 - val_accuracy: 0.9930\n",
      "Epoch 624/1000\n",
      "5700/5700 [==============================] - 1s 247us/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0329 - val_accuracy: 0.9939\n",
      "Epoch 625/1000\n",
      "5700/5700 [==============================] - 2s 289us/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0344 - val_accuracy: 0.9922\n",
      "Epoch 626/1000\n",
      "5700/5700 [==============================] - 1s 260us/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0353 - val_accuracy: 0.9926\n",
      "Epoch 627/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0100 - accuracy: 0.9961 - val_loss: 0.0319 - val_accuracy: 0.9926\n",
      "Epoch 628/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0361 - val_accuracy: 0.9935\n",
      "Epoch 629/1000\n",
      "5700/5700 [==============================] - 2s 338us/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0374 - val_accuracy: 0.9906\n",
      "Epoch 630/1000\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 631/1000\n",
      "5700/5700 [==============================] - 2s 293us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0350 - val_accuracy: 0.9930\n",
      "Epoch 632/1000\n",
      "5700/5700 [==============================] - 1s 259us/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0391 - val_accuracy: 0.9914\n",
      "Epoch 633/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9922\n",
      "Epoch 634/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0343 - val_accuracy: 0.9922\n",
      "Epoch 635/1000\n",
      "5700/5700 [==============================] - 2s 289us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0316 - val_accuracy: 0.9939\n",
      "Epoch 636/1000\n",
      "5700/5700 [==============================] - 2s 347us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0363 - val_accuracy: 0.9910\n",
      "Epoch 637/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0320 - val_accuracy: 0.9922\n",
      "Epoch 638/1000\n",
      "5700/5700 [==============================] - 1s 236us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0340 - val_accuracy: 0.9926\n",
      "Epoch 639/1000\n",
      "5700/5700 [==============================] - 1s 247us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0340 - val_accuracy: 0.9930\n",
      "Epoch 640/1000\n",
      "5700/5700 [==============================] - 2s 340us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0348 - val_accuracy: 0.9914\n",
      "Epoch 641/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0377 - val_accuracy: 0.9926\n",
      "Epoch 642/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0321 - val_accuracy: 0.9914\n",
      "Epoch 643/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0323 - val_accuracy: 0.9918\n",
      "Epoch 644/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0368 - val_accuracy: 0.9926\n",
      "Epoch 645/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.0361 - val_accuracy: 0.9922\n",
      "Epoch 646/1000\n",
      "5700/5700 [==============================] - 2s 335us/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0315 - val_accuracy: 0.9922\n",
      "Epoch 647/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0343 - val_accuracy: 0.9935\n",
      "Epoch 648/1000\n",
      "5700/5700 [==============================] - 1s 256us/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0345 - val_accuracy: 0.9918\n",
      "Epoch 649/1000\n",
      "5700/5700 [==============================] - 2s 304us/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0372 - val_accuracy: 0.9939\n",
      "Epoch 650/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0352 - val_accuracy: 0.9935\n",
      "Epoch 651/1000\n",
      "5700/5700 [==============================] - 1s 226us/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0311 - val_accuracy: 0.9935\n",
      "Epoch 652/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 653/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0318 - val_accuracy: 0.9922\n",
      "Epoch 654/1000\n",
      "5700/5700 [==============================] - 1s 253us/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0332 - val_accuracy: 0.9914\n",
      "Epoch 655/1000\n",
      "5700/5700 [==============================] - 2s 331us/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0351 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      "5700/5700 [==============================] - 1s 262us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 657/1000\n",
      "5700/5700 [==============================] - 2s 300us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0312 - val_accuracy: 0.9930\n",
      "Epoch 658/1000\n",
      "5700/5700 [==============================] - 2s 271us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0301 - val_accuracy: 0.9935\n",
      "Epoch 659/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0371 - val_accuracy: 0.9918\n",
      "Epoch 660/1000\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
      "Epoch 661/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0323 - val_accuracy: 0.9935\n",
      "Epoch 662/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0318 - val_accuracy: 0.9918\n",
      "Epoch 663/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0342 - val_accuracy: 0.9930\n",
      "Epoch 664/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0353 - val_accuracy: 0.9939\n",
      "Epoch 665/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0321 - val_accuracy: 0.9930\n",
      "Epoch 666/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0324 - val_accuracy: 0.9922\n",
      "Epoch 667/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0314 - val_accuracy: 0.9939\n",
      "Epoch 668/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0351 - val_accuracy: 0.9926\n",
      "Epoch 669/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 670/1000\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0359 - val_accuracy: 0.9910\n",
      "Epoch 671/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0327 - val_accuracy: 0.9930\n",
      "Epoch 672/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0330 - val_accuracy: 0.9939\n",
      "Epoch 673/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9935\n",
      "Epoch 674/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
      "Epoch 675/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0317 - val_accuracy: 0.9939\n",
      "Epoch 676/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0352 - val_accuracy: 0.9918\n",
      "Epoch 677/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0311 - val_accuracy: 0.9939\n",
      "Epoch 678/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0327 - val_accuracy: 0.9926\n",
      "Epoch 679/1000\n",
      "5700/5700 [==============================] - 1s 220us/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0335 - val_accuracy: 0.9918\n",
      "Epoch 680/1000\n",
      "5700/5700 [==============================] - 1s 198us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0315 - val_accuracy: 0.9935\n",
      "Epoch 681/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0406 - val_accuracy: 0.9926\n",
      "Epoch 682/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0317 - val_accuracy: 0.9918\n",
      "Epoch 683/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0307 - val_accuracy: 0.9935\n",
      "Epoch 684/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 685/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 0.0323 - val_accuracy: 0.9906\n",
      "Epoch 686/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9939\n",
      "Epoch 687/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0304 - val_accuracy: 0.9935\n",
      "Epoch 688/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0333 - val_accuracy: 0.9939\n",
      "Epoch 689/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0358 - val_accuracy: 0.9918\n",
      "Epoch 690/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0367 - val_accuracy: 0.9926\n",
      "Epoch 691/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.0374 - val_accuracy: 0.9914\n",
      "Epoch 692/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0361 - val_accuracy: 0.9918\n",
      "Epoch 693/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0329 - val_accuracy: 0.9930\n",
      "Epoch 694/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
      "Epoch 695/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 696/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0381 - val_accuracy: 0.9922\n",
      "Epoch 697/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0335 - val_accuracy: 0.9939\n",
      "Epoch 698/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0370 - val_accuracy: 0.9918\n",
      "Epoch 699/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0359 - val_accuracy: 0.9939\n",
      "Epoch 700/1000\n",
      "5700/5700 [==============================] - 1s 197us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0360 - val_accuracy: 0.9906\n",
      "Epoch 701/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 702/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 703/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0384 - val_accuracy: 0.9922\n",
      "Epoch 704/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0343 - val_accuracy: 0.9918\n",
      "Epoch 705/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0379 - val_accuracy: 0.9926\n",
      "Epoch 706/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 707/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0345 - val_accuracy: 0.9926\n",
      "Epoch 708/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 709/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0362 - val_accuracy: 0.9926\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0344 - val_accuracy: 0.9906\n",
      "Epoch 711/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0350 - val_accuracy: 0.9930\n",
      "Epoch 712/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
      "Epoch 713/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0362 - val_accuracy: 0.9918\n",
      "Epoch 714/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0359 - val_accuracy: 0.9922\n",
      "Epoch 715/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0324 - val_accuracy: 0.9922\n",
      "Epoch 716/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0362 - val_accuracy: 0.9922\n",
      "Epoch 717/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 718/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 719/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0349 - val_accuracy: 0.9922\n",
      "Epoch 720/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0393 - val_accuracy: 0.9922\n",
      "Epoch 721/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0294 - val_accuracy: 0.9922\n",
      "Epoch 722/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0376 - val_accuracy: 0.9910\n",
      "Epoch 723/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0326 - val_accuracy: 0.9922\n",
      "Epoch 724/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0372 - val_accuracy: 0.9914\n",
      "Epoch 725/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0351 - val_accuracy: 0.9910\n",
      "Epoch 726/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0376 - val_accuracy: 0.9918\n",
      "Epoch 727/1000\n",
      "5700/5700 [==============================] - 1s 196us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 728/1000\n",
      "5700/5700 [==============================] - 1s 197us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0329 - val_accuracy: 0.9922\n",
      "Epoch 729/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0332 - val_accuracy: 0.9914\n",
      "Epoch 730/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0409 - val_accuracy: 0.9906\n",
      "Epoch 731/1000\n",
      "5700/5700 [==============================] - 1s 197us/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 732/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.0324 - val_accuracy: 0.9922\n",
      "Epoch 733/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9930\n",
      "Epoch 734/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.0359 - val_accuracy: 0.9922\n",
      "Epoch 735/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 736/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0310 - val_accuracy: 0.9926\n",
      "Epoch 737/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0299 - val_accuracy: 0.9935\n",
      "Epoch 738/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0330 - val_accuracy: 0.9922\n",
      "Epoch 739/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 740/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0364 - val_accuracy: 0.9930\n",
      "Epoch 741/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9926\n",
      "Epoch 742/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.0347 - val_accuracy: 0.9914\n",
      "Epoch 743/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0354 - val_accuracy: 0.9930\n",
      "Epoch 744/1000\n",
      "5700/5700 [==============================] - 1s 198us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0366 - val_accuracy: 0.9926\n",
      "Epoch 745/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0394 - val_accuracy: 0.9914\n",
      "Epoch 746/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0315 - val_accuracy: 0.9939\n",
      "Epoch 747/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0362 - val_accuracy: 0.9930\n",
      "Epoch 748/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
      "Epoch 749/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.0374 - val_accuracy: 0.9930\n",
      "Epoch 750/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 751/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0342 - val_accuracy: 0.9935\n",
      "Epoch 752/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0368 - val_accuracy: 0.9930\n",
      "Epoch 753/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0339 - val_accuracy: 0.9926\n",
      "Epoch 754/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0311 - val_accuracy: 0.9939\n",
      "Epoch 755/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.0318 - val_accuracy: 0.9939\n",
      "Epoch 756/1000\n",
      "5700/5700 [==============================] - 1s 208us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0358 - val_accuracy: 0.9914\n",
      "Epoch 757/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0339 - val_accuracy: 0.9930\n",
      "Epoch 758/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0319 - val_accuracy: 0.9918\n",
      "Epoch 759/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 760/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0333 - val_accuracy: 0.9935\n",
      "Epoch 761/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0385 - val_accuracy: 0.9922\n",
      "Epoch 762/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0315 - val_accuracy: 0.9930\n",
      "Epoch 763/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0345 - val_accuracy: 0.9935\n",
      "Epoch 764/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0362 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0331 - val_accuracy: 0.9935\n",
      "Epoch 766/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0362 - val_accuracy: 0.9930\n",
      "Epoch 767/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0365 - val_accuracy: 0.9926\n",
      "Epoch 768/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0348 - val_accuracy: 0.9906\n",
      "Epoch 769/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0361 - val_accuracy: 0.9930\n",
      "Epoch 770/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
      "Epoch 771/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0365 - val_accuracy: 0.9922\n",
      "Epoch 772/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 773/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0352 - val_accuracy: 0.9918\n",
      "Epoch 774/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0353 - val_accuracy: 0.9939\n",
      "Epoch 775/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 776/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0350 - val_accuracy: 0.9935\n",
      "Epoch 777/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0371 - val_accuracy: 0.9926\n",
      "Epoch 778/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9930\n",
      "Epoch 779/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0366 - val_accuracy: 0.9922\n",
      "Epoch 780/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0326 - val_accuracy: 0.9930\n",
      "Epoch 781/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0335 - val_accuracy: 0.9943\n",
      "Epoch 782/1000\n",
      "5700/5700 [==============================] - 1s 259us/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0337 - val_accuracy: 0.9906\n",
      "Epoch 783/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.0346 - val_accuracy: 0.9935\n",
      "Epoch 784/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0331 - val_accuracy: 0.9926\n",
      "Epoch 785/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0330 - val_accuracy: 0.9947\n",
      "Epoch 786/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0417 - val_accuracy: 0.9914\n",
      "Epoch 787/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0439 - val_accuracy: 0.9918\n",
      "Epoch 788/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0430 - val_accuracy: 0.9918\n",
      "Epoch 789/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0406 - val_accuracy: 0.9926\n",
      "Epoch 790/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0443 - val_accuracy: 0.9926\n",
      "Epoch 791/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0401 - val_accuracy: 0.9947\n",
      "Epoch 792/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0414 - val_accuracy: 0.9926\n",
      "Epoch 793/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0428 - val_accuracy: 0.9914\n",
      "Epoch 794/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0384 - val_accuracy: 0.9922\n",
      "Epoch 795/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0438 - val_accuracy: 0.9910\n",
      "Epoch 796/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0394 - val_accuracy: 0.9926\n",
      "Epoch 797/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0421 - val_accuracy: 0.9922\n",
      "Epoch 798/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0427 - val_accuracy: 0.9910\n",
      "Epoch 799/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0404 - val_accuracy: 0.9926\n",
      "Epoch 800/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0348 - val_accuracy: 0.9914\n",
      "Epoch 801/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0454 - val_accuracy: 0.9906\n",
      "Epoch 802/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 803/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0398 - val_accuracy: 0.9914\n",
      "Epoch 804/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0425 - val_accuracy: 0.9930\n",
      "Epoch 805/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 0.0384 - val_accuracy: 0.9930\n",
      "Epoch 806/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0429 - val_accuracy: 0.9922\n",
      "Epoch 807/1000\n",
      "5700/5700 [==============================] - 1s 255us/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "Epoch 808/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9918\n",
      "Epoch 809/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0362 - val_accuracy: 0.9939\n",
      "Epoch 810/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
      "Epoch 811/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0450 - val_accuracy: 0.9918\n",
      "Epoch 812/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 813/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0346 - val_accuracy: 0.9926\n",
      "Epoch 814/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0356 - val_accuracy: 0.9939\n",
      "Epoch 815/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0351 - val_accuracy: 0.9922\n",
      "Epoch 816/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0379 - val_accuracy: 0.9926\n",
      "Epoch 817/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0356 - val_accuracy: 0.9926\n",
      "Epoch 818/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0386 - val_accuracy: 0.9914\n",
      "Epoch 819/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
      "Epoch 820/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 821/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0394 - val_accuracy: 0.9918\n",
      "Epoch 822/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0396 - val_accuracy: 0.9914\n",
      "Epoch 823/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0374 - val_accuracy: 0.9926\n",
      "Epoch 824/1000\n",
      "5700/5700 [==============================] - 2s 280us/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9918\n",
      "Epoch 825/1000\n",
      "5700/5700 [==============================] - 2s 385us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0363 - val_accuracy: 0.9914\n",
      "Epoch 826/1000\n",
      "5700/5700 [==============================] - 2s 355us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0348 - val_accuracy: 0.9922\n",
      "Epoch 827/1000\n",
      "5700/5700 [==============================] - 2s 432us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0343 - val_accuracy: 0.9926\n",
      "Epoch 828/1000\n",
      "5700/5700 [==============================] - 2s 428us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0342 - val_accuracy: 0.9939\n",
      "Epoch 829/1000\n",
      "5700/5700 [==============================] - 2s 345us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0351 - val_accuracy: 0.9918\n",
      "Epoch 830/1000\n",
      "5700/5700 [==============================] - 2s 402us/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0350 - val_accuracy: 0.9922\n",
      "Epoch 831/1000\n",
      "5700/5700 [==============================] - 1s 235us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0362 - val_accuracy: 0.9926\n",
      "Epoch 832/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0369 - val_accuracy: 0.9914\n",
      "Epoch 833/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9939\n",
      "Epoch 834/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0334 - val_accuracy: 0.9922\n",
      "Epoch 835/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0342 - val_accuracy: 0.9926\n",
      "Epoch 836/1000\n",
      "5700/5700 [==============================] - 1s 229us/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
      "Epoch 837/1000\n",
      "5700/5700 [==============================] - 1s 222us/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0445 - val_accuracy: 0.9914\n",
      "Epoch 838/1000\n",
      "5700/5700 [==============================] - 1s 234us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0328 - val_accuracy: 0.9930\n",
      "Epoch 839/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0370 - val_accuracy: 0.9914\n",
      "Epoch 840/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0333 - val_accuracy: 0.9918\n",
      "Epoch 841/1000\n",
      "5700/5700 [==============================] - 1s 227us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 842/1000\n",
      "5700/5700 [==============================] - 2s 313us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0375 - val_accuracy: 0.9930\n",
      "Epoch 843/1000\n",
      "5700/5700 [==============================] - 2s 436us/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0388 - val_accuracy: 0.9939\n",
      "Epoch 844/1000\n",
      "5700/5700 [==============================] - 2s 420us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0361 - val_accuracy: 0.9926\n",
      "Epoch 845/1000\n",
      "5700/5700 [==============================] - 2s 436us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 846/1000\n",
      "5700/5700 [==============================] - 2s 380us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0338 - val_accuracy: 0.9922\n",
      "Epoch 847/1000\n",
      "5700/5700 [==============================] - 2s 349us/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0306 - val_accuracy: 0.9922\n",
      "Epoch 848/1000\n",
      "5700/5700 [==============================] - 2s 382us/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0355 - val_accuracy: 0.9926\n",
      "Epoch 849/1000\n",
      "5700/5700 [==============================] - 2s 329us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0333 - val_accuracy: 0.9935\n",
      "Epoch 850/1000\n",
      "5700/5700 [==============================] - 2s 351us/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9906\n",
      "Epoch 851/1000\n",
      "5700/5700 [==============================] - 2s 352us/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 852/1000\n",
      "5700/5700 [==============================] - 2s 356us/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.0355 - val_accuracy: 0.9930\n",
      "Epoch 853/1000\n",
      "5700/5700 [==============================] - 2s 333us/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0427 - val_accuracy: 0.9918\n",
      "Epoch 854/1000\n",
      "5700/5700 [==============================] - 2s 331us/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9935\n",
      "Epoch 855/1000\n",
      "5700/5700 [==============================] - 2s 283us/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0342 - val_accuracy: 0.9935\n",
      "Epoch 856/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0387 - val_accuracy: 0.9926\n",
      "Epoch 857/1000\n",
      "5700/5700 [==============================] - 1s 209us/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0333 - val_accuracy: 0.9935\n",
      "Epoch 858/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.0353 - val_accuracy: 0.9922\n",
      "Epoch 859/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
      "Epoch 860/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0372 - val_accuracy: 0.9914\n",
      "Epoch 861/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0354 - val_accuracy: 0.9918\n",
      "Epoch 862/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0340 - val_accuracy: 0.9943\n",
      "Epoch 863/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 864/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 865/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0381 - val_accuracy: 0.9935\n",
      "Epoch 866/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0357 - val_accuracy: 0.9926\n",
      "Epoch 867/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0351 - val_accuracy: 0.9930\n",
      "Epoch 868/1000\n",
      "5700/5700 [==============================] - 2s 299us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0389 - val_accuracy: 0.9930\n",
      "Epoch 869/1000\n",
      "5700/5700 [==============================] - 2s 351us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0370 - val_accuracy: 0.9930\n",
      "Epoch 870/1000\n",
      "5700/5700 [==============================] - 2s 322us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0352 - val_accuracy: 0.9935\n",
      "Epoch 871/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0382 - val_accuracy: 0.9918\n",
      "Epoch 872/1000\n",
      "5700/5700 [==============================] - 1s 212us/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0407 - val_accuracy: 0.9914\n",
      "Epoch 873/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0397 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9914\n",
      "Epoch 875/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0369 - val_accuracy: 0.9918\n",
      "Epoch 876/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0294 - val_accuracy: 0.9935\n",
      "Epoch 877/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0333 - val_accuracy: 0.9930\n",
      "Epoch 878/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 879/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0356 - val_accuracy: 0.9918\n",
      "Epoch 880/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0349 - val_accuracy: 0.9926\n",
      "Epoch 881/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0325 - val_accuracy: 0.9935\n",
      "Epoch 882/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0358 - val_accuracy: 0.9918\n",
      "Epoch 883/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0357 - val_accuracy: 0.9918\n",
      "Epoch 884/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0326 - val_accuracy: 0.9935\n",
      "Epoch 885/1000\n",
      "5700/5700 [==============================] - 1s 228us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0329 - val_accuracy: 0.9926\n",
      "Epoch 886/1000\n",
      "5700/5700 [==============================] - 1s 219us/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.0349 - val_accuracy: 0.9939\n",
      "Epoch 887/1000\n",
      "5700/5700 [==============================] - 2s 342us/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0440 - val_accuracy: 0.9906\n",
      "Epoch 888/1000\n",
      "5700/5700 [==============================] - 3s 468us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0385 - val_accuracy: 0.9943\n",
      "Epoch 889/1000\n",
      "5700/5700 [==============================] - 1s 249us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
      "Epoch 890/1000\n",
      "5700/5700 [==============================] - 2s 272us/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0340 - val_accuracy: 0.9914\n",
      "Epoch 891/1000\n",
      "5700/5700 [==============================] - 2s 334us/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0363 - val_accuracy: 0.9926\n",
      "Epoch 892/1000\n",
      "5700/5700 [==============================] - 2s 353us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0305 - val_accuracy: 0.9910\n",
      "Epoch 893/1000\n",
      "5700/5700 [==============================] - 2s 389us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0287 - val_accuracy: 0.9935\n",
      "Epoch 894/1000\n",
      "5700/5700 [==============================] - 2s 318us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0312 - val_accuracy: 0.9922\n",
      "Epoch 895/1000\n",
      "5700/5700 [==============================] - 2s 353us/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0307 - val_accuracy: 0.9926\n",
      "Epoch 896/1000\n",
      "5700/5700 [==============================] - 2s 354us/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0336 - val_accuracy: 0.9939\n",
      "Epoch 897/1000\n",
      "5700/5700 [==============================] - 2s 360us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0365 - val_accuracy: 0.9922\n",
      "Epoch 898/1000\n",
      "5700/5700 [==============================] - 2s 378us/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0360 - val_accuracy: 0.9910\n",
      "Epoch 899/1000\n",
      "5700/5700 [==============================] - 2s 420us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0346 - val_accuracy: 0.9918\n",
      "Epoch 900/1000\n",
      "5700/5700 [==============================] - 2s 306us/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 901/1000\n",
      "5700/5700 [==============================] - 1s 217us/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
      "Epoch 902/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0386 - val_accuracy: 0.9914\n",
      "Epoch 903/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0406 - val_accuracy: 0.9930\n",
      "Epoch 904/1000\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.0424 - val_accuracy: 0.9906\n",
      "Epoch 905/1000\n",
      "5700/5700 [==============================] - 2s 348us/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0419 - val_accuracy: 0.9930\n",
      "Epoch 906/1000\n",
      "5700/5700 [==============================] - 2s 303us/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0419 - val_accuracy: 0.9926\n",
      "Epoch 907/1000\n",
      "5700/5700 [==============================] - 2s 296us/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0397 - val_accuracy: 0.9947\n",
      "Epoch 908/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0406 - val_accuracy: 0.9922\n",
      "Epoch 909/1000\n",
      "5700/5700 [==============================] - 1s 210us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0428 - val_accuracy: 0.9930\n",
      "Epoch 910/1000\n",
      "5700/5700 [==============================] - 2s 305us/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.0457 - val_accuracy: 0.9910\n",
      "Epoch 911/1000\n",
      "5700/5700 [==============================] - 2s 266us/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0404 - val_accuracy: 0.9926\n",
      "Epoch 912/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0423 - val_accuracy: 0.9930\n",
      "Epoch 913/1000\n",
      "5700/5700 [==============================] - 1s 258us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0372 - val_accuracy: 0.9935\n",
      "Epoch 914/1000\n",
      "5700/5700 [==============================] - 1s 233us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0394 - val_accuracy: 0.9930\n",
      "Epoch 915/1000\n",
      "5700/5700 [==============================] - 2s 328us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0412 - val_accuracy: 0.9914\n",
      "Epoch 916/1000\n",
      "5700/5700 [==============================] - 2s 335us/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0419 - val_accuracy: 0.9926\n",
      "Epoch 917/1000\n",
      "5700/5700 [==============================] - 2s 266us/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0359 - val_accuracy: 0.9926\n",
      "Epoch 918/1000\n",
      "5700/5700 [==============================] - 1s 242us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9922\n",
      "Epoch 919/1000\n",
      "5700/5700 [==============================] - 1s 221us/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0392 - val_accuracy: 0.9914\n",
      "Epoch 920/1000\n",
      "5700/5700 [==============================] - 1s 246us/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0415 - val_accuracy: 0.9926\n",
      "Epoch 921/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0365 - val_accuracy: 0.9918\n",
      "Epoch 922/1000\n",
      "5700/5700 [==============================] - 2s 278us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0299 - val_accuracy: 0.9939\n",
      "Epoch 923/1000\n",
      "5700/5700 [==============================] - 2s 313us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0332 - val_accuracy: 0.9935\n",
      "Epoch 924/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0329 - val_accuracy: 0.9906\n",
      "Epoch 925/1000\n",
      "5700/5700 [==============================] - 1s 230us/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0336 - val_accuracy: 0.9930\n",
      "Epoch 926/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0366 - val_accuracy: 0.9935\n",
      "Epoch 927/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0315 - val_accuracy: 0.9926\n",
      "Epoch 928/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.0338 - val_accuracy: 0.9926\n",
      "Epoch 929/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0345 - val_accuracy: 0.9922\n",
      "Epoch 930/1000\n",
      "5700/5700 [==============================] - 1s 197us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0397 - val_accuracy: 0.9926\n",
      "Epoch 931/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
      "Epoch 932/1000\n",
      "5700/5700 [==============================] - 1s 206us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0367 - val_accuracy: 0.9926\n",
      "Epoch 933/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9926\n",
      "Epoch 934/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0382 - val_accuracy: 0.9918\n",
      "Epoch 935/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9926\n",
      "Epoch 936/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9930\n",
      "Epoch 937/1000\n",
      "5700/5700 [==============================] - 1s 198us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0340 - val_accuracy: 0.9910\n",
      "Epoch 938/1000\n",
      "5700/5700 [==============================] - 1s 216us/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0350 - val_accuracy: 0.9926\n",
      "Epoch 939/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0349 - val_accuracy: 0.9914\n",
      "Epoch 940/1000\n",
      "5700/5700 [==============================] - 1s 214us/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0332 - val_accuracy: 0.9930\n",
      "Epoch 941/1000\n",
      "5700/5700 [==============================] - 3s 491us/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0343 - val_accuracy: 0.9930\n",
      "Epoch 942/1000\n",
      "5700/5700 [==============================] - 2s 279us/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0332 - val_accuracy: 0.9926\n",
      "Epoch 943/1000\n",
      "5700/5700 [==============================] - 2s 313us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0362 - val_accuracy: 0.9930\n",
      "Epoch 944/1000\n",
      "5700/5700 [==============================] - 2s 274us/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0336 - val_accuracy: 0.9930\n",
      "Epoch 945/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0372 - val_accuracy: 0.9930\n",
      "Epoch 946/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 947/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0330 - val_accuracy: 0.9922\n",
      "Epoch 948/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0346 - val_accuracy: 0.9930\n",
      "Epoch 949/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0387 - val_accuracy: 0.9898\n",
      "Epoch 950/1000\n",
      "5700/5700 [==============================] - 1s 223us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0354 - val_accuracy: 0.9918\n",
      "Epoch 951/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0415 - val_accuracy: 0.9910\n",
      "Epoch 952/1000\n",
      "5700/5700 [==============================] - 1s 257us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.0356 - val_accuracy: 0.9935\n",
      "Epoch 953/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0378 - val_accuracy: 0.9922\n",
      "Epoch 954/1000\n",
      "5700/5700 [==============================] - 1s 198us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0385 - val_accuracy: 0.9918\n",
      "Epoch 955/1000\n",
      "5700/5700 [==============================] - 1s 238us/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0355 - val_accuracy: 0.9922\n",
      "Epoch 956/1000\n",
      "5700/5700 [==============================] - 1s 244us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0317 - val_accuracy: 0.9939\n",
      "Epoch 957/1000\n",
      "5700/5700 [==============================] - 2s 274us/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0364 - val_accuracy: 0.9906\n",
      "Epoch 958/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0345 - val_accuracy: 0.9947\n",
      "Epoch 959/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0311 - val_accuracy: 0.9939\n",
      "Epoch 960/1000\n",
      "5700/5700 [==============================] - 1s 225us/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0415 - val_accuracy: 0.9918\n",
      "Epoch 961/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0339 - val_accuracy: 0.9930\n",
      "Epoch 962/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9939\n",
      "Epoch 963/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
      "Epoch 964/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0328 - val_accuracy: 0.9939\n",
      "Epoch 965/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0337 - val_accuracy: 0.9935\n",
      "Epoch 966/1000\n",
      "5700/5700 [==============================] - 2s 361us/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0385 - val_accuracy: 0.9926\n",
      "Epoch 967/1000\n",
      "5700/5700 [==============================] - 2s 353us/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9926\n",
      "Epoch 968/1000\n",
      "5700/5700 [==============================] - 2s 326us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0365 - val_accuracy: 0.9939\n",
      "Epoch 969/1000\n",
      "5700/5700 [==============================] - 2s 336us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0380 - val_accuracy: 0.9922\n",
      "Epoch 970/1000\n",
      "5700/5700 [==============================] - 1s 237us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0423 - val_accuracy: 0.9906\n",
      "Epoch 971/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0391 - val_accuracy: 0.9926\n",
      "Epoch 972/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0389 - val_accuracy: 0.9910\n",
      "Epoch 973/1000\n",
      "5700/5700 [==============================] - 1s 203us/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0349 - val_accuracy: 0.9926\n",
      "Epoch 974/1000\n",
      "5700/5700 [==============================] - 1s 207us/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0385 - val_accuracy: 0.9918\n",
      "Epoch 975/1000\n",
      "5700/5700 [==============================] - 2s 304us/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 976/1000\n",
      "5700/5700 [==============================] - 1s 253us/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0360 - val_accuracy: 0.9926\n",
      "Epoch 977/1000\n",
      "5700/5700 [==============================] - 1s 215us/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0355 - val_accuracy: 0.9914\n",
      "Epoch 978/1000\n",
      "5700/5700 [==============================] - 1s 231us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0371 - val_accuracy: 0.9910\n",
      "Epoch 979/1000\n",
      "5700/5700 [==============================] - 1s 232us/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0333 - val_accuracy: 0.9926\n",
      "Epoch 980/1000\n",
      "5700/5700 [==============================] - 1s 239us/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0342 - val_accuracy: 0.9922\n",
      "Epoch 981/1000\n",
      "5700/5700 [==============================] - 1s 224us/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0343 - val_accuracy: 0.9918\n",
      "Epoch 982/1000\n",
      "5700/5700 [==============================] - 1s 205us/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.0364 - val_accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0359 - val_accuracy: 0.9939\n",
      "Epoch 984/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
      "Epoch 985/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0308 - val_accuracy: 0.9930\n",
      "Epoch 986/1000\n",
      "5700/5700 [==============================] - 1s 218us/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.0300 - val_accuracy: 0.9955\n",
      "Epoch 987/1000\n",
      "5700/5700 [==============================] - 1s 204us/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 988/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 989/1000\n",
      "5700/5700 [==============================] - 1s 201us/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0285 - val_accuracy: 0.9951\n",
      "Epoch 990/1000\n",
      "5700/5700 [==============================] - 1s 202us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0291 - val_accuracy: 0.9926\n",
      "Epoch 991/1000\n",
      "5700/5700 [==============================] - 1s 200us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 992/1000\n",
      "5700/5700 [==============================] - 1s 199us/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0341 - val_accuracy: 0.9910\n",
      "Epoch 993/1000\n",
      "5700/5700 [==============================] - 2s 352us/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0336 - val_accuracy: 0.9922\n",
      "Epoch 994/1000\n",
      "5700/5700 [==============================] - 2s 276us/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 995/1000\n",
      "5700/5700 [==============================] - 2s 404us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0334 - val_accuracy: 0.9935\n",
      "Epoch 996/1000\n",
      "5700/5700 [==============================] - 3s 491us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0273 - val_accuracy: 0.9930\n",
      "Epoch 997/1000\n",
      "5700/5700 [==============================] - 2s 281us/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0303 - val_accuracy: 0.9935\n",
      "Epoch 998/1000\n",
      "5700/5700 [==============================] - 2s 318us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0372 - val_accuracy: 0.9926\n",
      "Epoch 999/1000\n",
      "5700/5700 [==============================] - 2s 304us/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0399 - val_accuracy: 0.9930\n",
      "Epoch 1000/1000\n",
      "5700/5700 [==============================] - 1s 211us/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0398 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model()\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443/2443 [==============================] - 0s 20us/step\n",
      "Loss 0.027835, Accuracy 0.990585\n",
      "Loss 0.022286, Accuracy 0.992223\n",
      "Loss 0.039783, Accuracy 0.992223\n"
     ]
    }
   ],
   "source": [
    "test_loss_3, test_acc_3 = model3.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3['loss'], label='Train')\n",
    "plt.plot(history3['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant arguments are:\n",
    "\n",
    "* monitor: quantity to be monitored\n",
    "* patience: number of epochs with no improvement after which training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4560 samples, validate on 1140 samples\n",
      "Epoch 1/100\n",
      "4560/4560 [==============================] - 1s 262us/step - loss: 0.0871 - accuracy: 0.9792 - val_loss: 0.0364 - val_accuracy: 0.9904\n",
      "Epoch 2/100\n",
      "4560/4560 [==============================] - 1s 299us/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.0353 - val_accuracy: 0.9868\n",
      "Epoch 3/100\n",
      "4560/4560 [==============================] - 1s 224us/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.0345 - val_accuracy: 0.9904\n",
      "Epoch 4/100\n",
      "4560/4560 [==============================] - 1s 234us/step - loss: 0.0343 - accuracy: 0.9873 - val_loss: 0.0305 - val_accuracy: 0.9877\n",
      "Epoch 5/100\n",
      "4560/4560 [==============================] - 1s 240us/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.0299 - val_accuracy: 0.9904\n",
      "Epoch 6/100\n",
      "4560/4560 [==============================] - 1s 234us/step - loss: 0.0302 - accuracy: 0.9879 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
      "Epoch 7/100\n",
      "4560/4560 [==============================] - 1s 219us/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
      "Epoch 8/100\n",
      "4560/4560 [==============================] - 1s 200us/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.0289 - val_accuracy: 0.9904\n",
      "Epoch 9/100\n",
      "4560/4560 [==============================] - 1s 221us/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.0291 - val_accuracy: 0.9921\n",
      "Epoch 10/100\n",
      "4560/4560 [==============================] - 1s 207us/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
      "Epoch 11/100\n",
      "4560/4560 [==============================] - 1s 207us/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0406 - val_accuracy: 0.9842\n",
      "Epoch 12/100\n",
      "4560/4560 [==============================] - 1s 219us/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0277 - val_accuracy: 0.9912\n",
      "Epoch 13/100\n",
      "4560/4560 [==============================] - 1s 207us/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.0269 - val_accuracy: 0.9912\n",
      "Epoch 14/100\n",
      "4560/4560 [==============================] - 1s 203us/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.0263 - val_accuracy: 0.9930\n",
      "Epoch 15/100\n",
      "4560/4560 [==============================] - 1s 201us/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.0259 - val_accuracy: 0.9939\n",
      "Epoch 16/100\n",
      "4560/4560 [==============================] - 1s 204us/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0249 - val_accuracy: 0.9939\n",
      "Epoch 17/100\n",
      "4560/4560 [==============================] - 1s 206us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0302 - val_accuracy: 0.9904\n",
      "Epoch 18/100\n",
      "4560/4560 [==============================] - 1s 199us/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0256 - val_accuracy: 0.9947\n",
      "Epoch 19/100\n",
      "4560/4560 [==============================] - 1s 203us/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0282 - val_accuracy: 0.9912\n",
      "Epoch 20/100\n",
      "4560/4560 [==============================] - 1s 201us/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0297 - val_accuracy: 0.9912\n",
      "Epoch 21/100\n",
      "4560/4560 [==============================] - 1s 210us/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0270 - val_accuracy: 0.9921\n",
      "Epoch 22/100\n",
      "4560/4560 [==============================] - 1s 212us/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0254 - val_accuracy: 0.9939\n",
      "Epoch 23/100\n",
      "4560/4560 [==============================] - 1s 197us/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 24/100\n",
      "4560/4560 [==============================] - 1s 199us/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0380 - val_accuracy: 0.9904\n",
      "Epoch 25/100\n",
      "4560/4560 [==============================] - 1s 206us/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0277 - val_accuracy: 0.9939\n",
      "Epoch 26/100\n",
      "4560/4560 [==============================] - 1s 200us/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.0260 - val_accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model4 = build_model()\n",
    "history4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                      batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443/2443 [==============================] - 0s 24us/step\n",
      "Loss 0.027835, Accuracy 0.990585\n",
      "Loss 0.022286, Accuracy 0.992223\n",
      "Loss 0.039783, Accuracy 0.992223\n",
      "Loss 0.023513, Accuracy 0.991813\n"
     ]
    }
   ],
   "source": [
    "test_loss_4, test_acc_4 = model4.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_4, test_acc_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4560 samples, validate on 1140 samples\n",
      "Epoch 1/100\n",
      "4560/4560 [==============================] - 2s 345us/step - loss: 3.8268 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 2/100\n",
      "4560/4560 [==============================] - 1s 265us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 3/100\n",
      "4560/4560 [==============================] - 1s 256us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 4/100\n",
      "4560/4560 [==============================] - 1s 259us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 5/100\n",
      "4560/4560 [==============================] - 1s 255us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 6/100\n",
      "4560/4560 [==============================] - 1s 256us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 7/100\n",
      "4560/4560 [==============================] - 1s 257us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 8/100\n",
      "4560/4560 [==============================] - 1s 254us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 9/100\n",
      "4560/4560 [==============================] - 1s 258us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 10/100\n",
      "4560/4560 [==============================] - 1s 261us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 11/100\n",
      "4560/4560 [==============================] - 1s 264us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n",
      "Epoch 12/100\n",
      "4560/4560 [==============================] - 1s 258us/step - loss: 3.4640 - accuracy: 0.7851 - val_loss: 3.2519 - val_accuracy: 0.7982\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                    batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4560 samples, validate on 1140 samples\n",
      "Epoch 1/100\n",
      "4560/4560 [==============================] - 2s 394us/step - loss: 0.2033 - accuracy: 0.2996 - val_loss: 0.1540 - val_accuracy: 0.0035\n",
      "Epoch 2/100\n",
      "4560/4560 [==============================] - 1s 286us/step - loss: 0.1978 - accuracy: 0.0463 - val_loss: 0.1409 - val_accuracy: 0.0053\n",
      "Epoch 3/100\n",
      "4560/4560 [==============================] - 1s 284us/step - loss: 0.2183 - accuracy: 0.0162 - val_loss: 0.1544 - val_accuracy: 0.0035\n",
      "Epoch 4/100\n",
      "4560/4560 [==============================] - 1s 290us/step - loss: 0.2069 - accuracy: 0.0061 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4560/4560 [==============================] - 1s 284us/step - loss: 0.2010 - accuracy: 0.0055 - val_loss: 0.3429 - val_accuracy: 0.0088\n",
      "Epoch 6/100\n",
      "4560/4560 [==============================] - 1s 287us/step - loss: 0.2120 - accuracy: 0.0059 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4560/4560 [==============================] - 1s 289us/step - loss: 0.2156 - accuracy: 0.0066 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4560/4560 [==============================] - 1s 281us/step - loss: 0.1928 - accuracy: 0.0015 - val_loss: 0.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4560/4560 [==============================] - 1s 293us/step - loss: 0.1902 - accuracy: 0.0035 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4560/4560 [==============================] - 1s 287us/step - loss: 0.2030 - accuracy: 6.5789e-04 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4560/4560 [==============================] - 1s 312us/step - loss: 0.1964 - accuracy: 0.0013 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4560/4560 [==============================] - 1s 287us/step - loss: 0.1994 - accuracy: 4.3860e-04 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=100, batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443/2443 [==============================] - 0s 117us/step\n",
      "2443/2443 [==============================] - 0s 95us/step\n",
      "2443/2443 [==============================] - 0s 101us/step\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "loss_NOREG, acc_NOREG = best_NOREG_model.evaluate(X_test, y_test)\n",
    "loss_L2, acc_L2 = best_L2_model.evaluate(X_test, y_test)\n",
    "loss_DROPOUT, acc_DROPOUT = best_DROPOUT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.023647, Accuracy 0.992223\n",
      "Loss 3.424188, Accuracy 0.787556\n",
      "Loss 0.139118, Accuracy 0.004503\n"
     ]
    }
   ],
   "source": [
    "print('Loss %f, Accuracy %f' % (loss_NOREG, acc_NOREG))\n",
    "print('Loss %f, Accuracy %f' % (loss_L2, acc_L2))\n",
    "print('Loss %f, Accuracy %f' % (loss_DROPOUT, acc_DROPOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers=2, h_dim=64, activation='relu', optimizer='adam'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(h_dim, activation=activation, input_shape=(n_feature,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(h_dim, activation=activation))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = [1, 2, 3]\n",
    "h_dim = [32, 64, 128]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adagrad', 'adam']\n",
    "params = dict(optimizer=optimizer, n_layers=n_layers, h_dim=h_dim, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520/1520 [==============================] - 0s 123us/step\n",
      "1520/1520 [==============================] - 0s 138us/step\n",
      "1520/1520 [==============================] - 0s 185us/step\n",
      "1520/1520 [==============================] - 0s 187us/step\n",
      "1520/1520 [==============================] - 0s 146us/step\n",
      "1520/1520 [==============================] - 0s 168us/step\n",
      "1520/1520 [==============================] - 0s 171us/step\n",
      "1520/1520 [==============================] - 0s 171us/step\n",
      "1520/1520 [==============================] - 0s 311us/step\n",
      "1520/1520 [==============================] - 0s 203us/step\n",
      "1520/1520 [==============================] - 1s 368us/step\n",
      "1520/1520 [==============================] - 0s 215us/step\n",
      "1520/1520 [==============================] - 0s 215us/step\n",
      "1520/1520 [==============================] - 0s 202us/step\n",
      "1520/1520 [==============================] - 0s 205us/step\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "rnd = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=5, cv=3)\n",
    "rnd_result = rnd.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.162472 using {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 64, 'activation': 'tanh'}\n",
      "0.198995 (0.026375) with: {'optimizer': 'adam', 'n_layers': 2, 'h_dim': 128, 'activation': 'relu'}\n",
      "0.197968 (0.027118) with: {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 128, 'activation': 'tanh'}\n",
      "0.192295 (0.030733) with: {'optimizer': 'adagrad', 'n_layers': 3, 'h_dim': 64, 'activation': 'tanh'}\n",
      "0.162472 (0.019306) with: {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 64, 'activation': 'tanh'}\n",
      "1.256576 (1.563453) with: {'optimizer': 'adagrad', 'n_layers': 3, 'h_dim': 64, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (-rnd_result.best_score_, rnd_result.best_params_))\n",
    "means = rnd_result.cv_results_['mean_test_score']\n",
    "stds = rnd_result.cv_results_['std_test_score']\n",
    "params = rnd_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (-mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443/2443 [==============================] - 0s 154us/step\n",
      "Loss 0.145192, Accuracy 0.066312\n"
     ]
    }
   ],
   "source": [
    "clf = rnd_result.best_estimator_.model\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test)\n",
    "print('Loss %f, Accuracy %f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
